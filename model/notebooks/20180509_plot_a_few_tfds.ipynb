{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import glob\n",
    "\n",
    "import joypy\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import tftb\n",
    "\n",
    "from util import *\n",
    "\n",
    "figsize('inline_short')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio paths\n",
    "audio_paths = pd.DataFrame([\n",
    "    OrderedDict(\n",
    "        source=path.split('/')[-4],\n",
    "        species_code=path.split('/')[-3],\n",
    "        title=os.path.splitext(path.split('/')[-1])[0],\n",
    "        path=path,\n",
    "    )\n",
    "    for path in glob.glob(f'{peterson_dir}/*/audio/*')\n",
    "])\n",
    "display(\n",
    "    audio_paths[:5],\n",
    "    audio_paths.groupby(['source', 'species_code']).count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio from paths\n",
    "recs_2ch = (audio_paths\n",
    "    [lambda df: df.species_code == 'wlswar'].reset_index(drop=True)  # For faster dev\n",
    "    [:5]  # For faster dev\n",
    "    .assign(audio=lambda df: df.reset_index(drop=True).apply(axis=1, func=lambda rec:\n",
    "        (\n",
    "            print(f'Loading audio {rec.name + 1}/{len(df)}: {rec.path}') if rec.name % (np.ceil(len(df) / 5) or 1) == 0 else None,\n",
    "            audiosegment.from_file(rec.path),\n",
    "        )[-1]\n",
    "    ))\n",
    ")\n",
    "recs_2ch.audio[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = (recs_2ch\n",
    "    .assign(\n",
    "        # Merge stereo to mono so we don't get confused when handling samples (we don't care about stereo vs. mono)\n",
    "        audio=lambda df: df.audio.apply(lambda audio:\n",
    "            audio.resample(channels=1, sample_rate_Hz=standard_sample_rate_hz)\n",
    "            # audio.set_channels(1)  # TODO Any loss in fidelity by using .resample(channels=1)?\n",
    "        ),\n",
    "    )\n",
    "    .assign(\n",
    "        # Materialize audio samples\n",
    "        samples=lambda df: df.audio.map(lambda audio: audio.to_numpy_array()),\n",
    "    )\n",
    "    .pipe(df_reorder_cols, last=['path'])\n",
    ")\n",
    "recs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names for easier dev (better autocomplete)\n",
    "rec0 = recs.iloc[0]\n",
    "audio0 = rec0.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO How big of audio signals do we actually need to deal with?\n",
    "#   - How does pytftb structure its sampling for ACF/WVD?\n",
    "#   - [This was related to my scipy.signal.correlation attempt elsewhere, which was wrong-headed and I'm throwing away]\n",
    "(f, t, S) = Spectro(audio0, nperseg=512, overlap=0.5)\n",
    "display(\n",
    "    # The raw signal is big\n",
    "    audio0.to_numpy_array().shape,\n",
    "    # But these spectrogram outputs are not big...\n",
    "    f.shape,\n",
    "    t.shape,\n",
    "    S.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with with_figsize(aspect_ratio=1/10):\n",
    "    plt_audio_signal(audio0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "with with_figsize(aspect_ratio=1/5):\n",
    "    recs[1:2].apply(axis=1, func=lambda rec: (\n",
    "        Spectro(rec, nperseg=1024, overlap=0.5).plot(fancy=True),\n",
    "        plt.show(),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "figsize(aspect_ratio=1/2)\n",
    "# TODO\n",
    "#   - [x] Plot a cepstrum (spectrum(x) = FT(x), cepstrum(x) = IFT(log(abs(FT(x)))))\n",
    "#   - [ ] Grid these plots wide-ly and then plot a handful of different audios for comparison!\n",
    "\n",
    "(rec, _, x, sample_rate) = unpack_rec(audio0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Done! Mfcc looks like librosa (except librosa is lower resolution on t axis, and we don't care why). Next:\n",
    "#   - [x] Compare dct3 (idct) vs. dct2 (dct), since mfcc is supposed to be idct, not dct\n",
    "#   - [x] Leave the function params in place\n",
    "#   - [ ] Pick a sane default (2? 3? does it matter?)\n",
    "#   - [ ] Clean up Mfcc\n",
    "#   - [ ] Pop the stack!\n",
    "n_mfcc = 32\n",
    "dct_type = 3\n",
    "dct_norm = 'ortho'\n",
    "std = False\n",
    "Mfcc(x, mels_div=2, first_n_mfcc=n_mfcc, std=std, dct_type=dct_type, dct_norm=dct_norm).plot(show_audio=False, fancy=False)\n",
    "plt.title(f'n_mfcc={n_mfcc}, dct_type={dct_type}, dct_norm={dct_norm}')  # XXX\n",
    "plt.show()\n",
    "\n",
    "# M = librosa.feature.mfcc(x.astype(float), sample_rate, n_mfcc=n_mfcc)\n",
    "# M = (M - M.mean(axis=1)[:, np.newaxis]) / M.std(axis=1)[:, np.newaxis]  # Standardize\n",
    "# plt.pcolormesh(M)\n",
    "# plt.gca().yaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%5d'))\n",
    "# plt.gca().tick_params(labelsize=8)\n",
    "# [s.set_visible(False) for s in plt.gca().spines.values()]\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Try denoising: smoothing and/or filtering\n",
    "def zero_below(S, perc=75):\n",
    "    out = S.copy()\n",
    "    for ST, outT in [(S, out), (S.T, out.T)]:\n",
    "        for i in range(ST.shape[0]):\n",
    "            outT[i][ST[i] < np.percentile(ST[i], perc)] = 0\n",
    "    return out\n",
    "\n",
    "def zero_below_all(S, perc=75):\n",
    "    out = S.copy()\n",
    "    out[out < np.percentile(S, perc)] = 0\n",
    "    return out\n",
    "\n",
    "def smooth(S, kernel_size=3):\n",
    "    return scipy.signal.medfilt(S, kernel_size=kernel_size)\n",
    "\n",
    "with with_figsize(aspect_ratio=1/8):\n",
    "    audio = audio0[1000:3000]\n",
    "    (f, t, S) = Spectro(audio, nperseg=256, overlap=.9)\n",
    "    display(S.shape)\n",
    "    S_log1p = np.log1p(S)\n",
    "    kernel_size = 5\n",
    "    perc = 1\n",
    "    # plt.pcolormesh(t, f, np.log(S)); plt.show()\n",
    "    plt.pcolormesh(t, f, S_log1p); plt.show()\n",
    "    # plt.pcolormesh(t, f, zero_below(S_log1p)); plt.show()\n",
    "    # plt.pcolormesh(t, f, smooth(S_log1p)); plt.show()\n",
    "    # plt.pcolormesh(t, f, zero_below(smooth(S_log1p))); plt.show()\n",
    "    # plt.pcolormesh(t, f, smooth(zero_below(S_log1p))); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO What is FT(acf(x))? This seems like a common technique.\n",
    "with with_figsize(aspect_ratio=1/8):\n",
    "\n",
    "    x = audio0[1000:3000].to_numpy_array()\n",
    "    y = scipy.signal.correlate(x, x, mode='same')\n",
    "    yH = len(y) // 2\n",
    "    y = y[yH-500:yH+500]\n",
    "    display(\n",
    "        x.shape,\n",
    "        y.shape,\n",
    "        # audiosegment.from_numpy_array(x, 22050),\n",
    "    )\n",
    "\n",
    "    # XXX Some crap (corr directly on the visual spectros)\n",
    "    # (f, t, S) = Spectro(x, nperseg=256, overlap=.9)\n",
    "    # S = np.abs(S)\n",
    "    # acorr_in = S\n",
    "    # aS = scipy.signal.correlate(acorr_in, acorr_in, mode='same')\n",
    "    # display(\n",
    "    #     S.shape,\n",
    "    #     aS.shape,\n",
    "    # )\n",
    "    # plt.pcolormesh(t, f, np.abs(S)); plt.show()\n",
    "    # plt.pcolormesh(t, f, np.abs(aS)); plt.show()\n",
    "    # plt.pcolormesh(t, f, np.log(np.abs(S))); plt.show()\n",
    "    # plt.pcolormesh(t, f, np.log(np.abs(aS))); plt.show()\n",
    "    # plt.pcolormesh(t, f, np.log1p(np.abs(S))); plt.show()\n",
    "    # plt.pcolormesh(t, f, np.log1p(np.abs(aS))); plt.show()\n",
    "\n",
    "    plt_signal(x); plt.show()\n",
    "    plt.plot((np.abs(np.fft.rfft(x)) / 22050)**2 / 2); plt.show()\n",
    "    plt.plot(*scipy.signal.periodogram(x, fs=22050, scaling='spectrum')); plt.show()\n",
    "    Spectro(x, nperseg=256, overlap=.9).plot(); plt.show()\n",
    "    plt_signal(y); plt.show()\n",
    "    plt.plot((np.abs(np.fft.rfft(y)) / 22050)**2 / 2); plt.show()\n",
    "    plt.plot(*scipy.signal.periodogram(y, fs=22050, scaling='spectrum')); plt.show()\n",
    "    Spectro(y, nperseg=32, overlap=.95).plot(); plt.show()  # [Why isn't plt_spectro as good as plt.specgram?]\n",
    "    plt.specgram(y, NFFT=50, noverlap=49, Fs=22050); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ambiguity_function_via_spectro(x):\n",
    "\"\"\"\n",
    "A fast ambiguity function for signal x via 2D-FT on its (STFT) spectrogram:\n",
    "    A_x(ν,τ) = FT_{t->ν}(IFT_{τ<-f}(S_x(t,f)))\n",
    "\n",
    "This approach mimics QTFD relationship between the ambiguity function and WVD, which is slow to compute:\n",
    "    A_z(ν,τ) = FT_{t->ν}(IFT_{τ<-f}(W_z(t,f)))\n",
    "\"\"\"\n",
    "\n",
    "(f, t, S) = Spectro(\n",
    "    audio0[2000:3000],\n",
    "    nperseg=256,\n",
    "    overlap=0.8,\n",
    ")\n",
    "display(\n",
    "    t.shape,\n",
    "    f.shape,\n",
    "    S.shape,\n",
    ")\n",
    "\n",
    "plt.pcolormesh(t, f, np.log(S))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO A_x(ν,τ) = FT_{t->ν}(IFT_{τ<-f}(S_x(t,f)))\n",
    "# A = np.abs(S)\n",
    "# A = np.fft.fft2(S)  # Junk?\n",
    "# A = np.fft.fft2(np.abs(S))  # Hint of not junk...\n",
    "# A = np.fft.fft2(np.log(np.abs(S)))  # Junk?\n",
    "# A = np.fft.fft(axis=1, a=np.fft.ifft(axis=0, a=S))  # Junk?\n",
    "A = np.fft.fft(axis=1, a=np.fft.ifft(axis=0, a=np.abs(S)))  # Looks similar to fft2, above... maybe not junk?\n",
    "# A = np.fft.fft(axis=1, n=1*S.shape[1], a=np.fft.ifft(axis=0, n=1*S.shape[0], a=np.abs(S)))  # Better borders?\n",
    "# A = np.fft.fft(axis=1, n=8*S.shape[1], a=np.fft.ifft(axis=0, n=8*S.shape[0], a=np.abs(S)))  # Better borders?\n",
    "# A = np.fft.fft(axis=1, a=np.fft.ifft(axis=0, a=np.log(np.abs(S))))  # Junk?\n",
    "# TODO TODO Is we being drowned out by noise...? Next step: try on a toy signal with higher res and less noise!\n",
    "plt.pcolormesh(\n",
    "    # np.abs(A),\n",
    "    np.log(np.abs(A)),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Dev above\n",
    "# tau = ...\n",
    "# nu = ...\n",
    "# af = ...\n",
    "\n",
    "# with with_figsize('inline'):\n",
    "#     # plt.pcolormesh(tau, nu, af)  # TODO\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio0_sub = audio0[:100]  # wide_band[6.8s]\n",
    "# audio0_sub = audio0[1000:4000]\n",
    "# audio0_sub = audio0[2000:2500]\n",
    "# audio0_sub = audio0[1000:3000]  # .6s vs. 4s\n",
    "# audio0_sub = audio0[0000:5000]  # .7s vs. 9s\n",
    "x = audio0_sub.to_numpy_array()\n",
    "x_sample_rate = audio0_sub.frame_rate\n",
    "display(x.shape)\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with with_figsize(aspect_ratio=1/5):\n",
    "    Spectro(x, nperseg=512, overlap=0.5).plot(fancy=True, show_audio=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tftb.processing.ambiguity import narrow_band, wide_band\n",
    "waf, lag, doppler = wide_band(x, fmin=None, fmax=None, N=None)\n",
    "display(\n",
    "    waf.shape,\n",
    "    lag.shape,\n",
    "    doppler.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Downsample x before computing the AF!\n",
    "np.abs(waf[:10,:10])\n",
    "# plt.pcolormesh(lag, doppler, np.abs(waf) ** 1)  # TODO Blank plot...\n",
    "# TODO Both plt.pcolormesh and plt.contour go blank somewhere between i=4000 -> i=5000...\n",
    "with with_figsize('inline'):\n",
    "    i, j = 4000, 2205\n",
    "    plt.contour(lag[:j], doppler[:i], np.abs(waf)[:i,:j])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX PRETTY SLOW. don't use their spectrogram implementation\n",
    "# fwindow = signal.hamming(65)\n",
    "# %time spec = tftb.processing.Spectrogram(x, n_fbins=128, fwindow=fwindow); spec.run()\n",
    "# spec.plot(kind='contour', threshold=0.1, show_tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX SLOW AS FUCK, AND BLOWS UP RAM!\n",
    "# %time wvd = tftb.processing.WignerVilleDistribution(x); wvd.run()\n",
    "# wvd.plot(kind='cmap')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bubo-features (PYTHONSTARTUP)",
   "language": "python",
   "name": "bubo-features (PYTHONSTARTUP)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
