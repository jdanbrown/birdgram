{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(\n",
    "    'td .label-i.i-%-2s { color: white; background: %s; }' % (i, mpl.colors.rgb2hex(x))\n",
    "    for i, x in enumerate(take(50, cycle(chain(\n",
    "        islice(mpl.cm.tab20.colors, 0, None, 2),\n",
    "        islice(mpl.cm.tab20.colors, 1, None, 2),\n",
    "        mpl.cm.Pastel1.colors,\n",
    "    ))))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "3.889s"
   },
   "outputs": [],
   "source": [
    "# Debug mobile cosine_distance\n",
    "from notebooks import *\n",
    "sg.init(None)\n",
    "recs = sg.search_recs\n",
    "q = recs.query('xc_id == 417559').iloc[0]\n",
    "s = recs.query('xc_id == 416810').iloc[0]\n",
    "display(\n",
    "    sk.metrics.pairwise.distance_metrics()['cosine']([s.f_preds], [q.f_preds]),\n",
    "    np.dot(s.f_preds, q.f_preds) / np.linalg.norm(s.f_preds) / np.linalg.norm(q.f_preds),\n",
    "    1 - np.dot(s.f_preds, q.f_preds) / np.linalg.norm(s.f_preds) / np.linalg.norm(q.f_preds),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find search.classes_ for mobile\n",
    "from notebooks import *\n",
    "sg.init(None)\n",
    "display(\n",
    "    sk_dir_attrs(sg.search),\n",
    "    sg.search.classes_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([[1,2,3],[4,5,6]])\n",
    "np.maximum(2.5, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(2.0)\n",
    "np.log(2.0)\n",
    "np.log10(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([1, 2, 4, 7, 0])\n",
    "display(\n",
    "    np.diff(xs),\n",
    "    xs[1:] - xs[:-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply.outer([1,2], [-3,-5,-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3,5))\n",
    "np.zeros((3,5))[0]\n",
    "np.zeros((3,5))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 3\n",
    "cols   = 5\n",
    "weights = (np.random.rand(n_mels, cols) * 10).astype(int); weights\n",
    "enorm = (np.random.rand(n_mels) * 10).astype(int); enorm\n",
    "weights.shape\n",
    "enorm[:, np.newaxis].shape\n",
    "enorm[:, np.newaxis]\n",
    "np.broadcast_to(enorm[:, np.newaxis], (3,5))\n",
    "weights * enorm[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights\n",
    "weights**2\n",
    "weights*weights\n",
    "np.dot(weights, weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([[1,2,3],[4,5,6]]); S\n",
    "S[0] * S[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.signal.hann(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([[1,2,3],[4,5,6]]); S\n",
    "S**2\n",
    "(S**2).mean()\n",
    "S / np.sqrt((S ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_count   = 5286\n",
    "xs_count   = 5120\n",
    "nperseg    = 512\n",
    "noverlap   = 256\n",
    "win_length = nperseg\n",
    "hop_length = noverlap\n",
    "f          = win_length\n",
    "t_         = (xs_count - win_length) / hop_length + 1\n",
    "t          = int(t_)\n",
    "hops       = list(range(xs_count)[0 : xs_count - win_length : hop_length])\n",
    "dict(\n",
    "    xs_count=xs_count,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    f=f,\n",
    "    t_=t_,\n",
    "    t=t,\n",
    "    len_hops=len(hops),\n",
    "    hops=hops,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, w, h, exp in [\n",
    "    (14, 6, 3, 3),\n",
    "    (15, 6, 3, 4),\n",
    "    (16, 6, 3, 4),\n",
    "    (17, 6, 3, 4),\n",
    "    (18, 6, 3, 5),\n",
    "    (19, 6, 3, 5),\n",
    "    (5210, 512, 256, 0),\n",
    "]:\n",
    "    xs = range(n)\n",
    "    segs = list([x, x+w] for x in xs[0 : n-w : h])\n",
    "    t = (n - w) // h + 1\n",
    "    n_segs = len(segs)\n",
    "    display({\n",
    "        'n, w, h': (n, w, h),\n",
    "        't, n_segs': (t, n_segs),\n",
    "        # 'n/h': round(n/h, 3),\n",
    "        # '(n-w)/h': round((n-w)/h, 3),\n",
    "        # '(n-w)/h+1': round((n-w)/h+1, 3),\n",
    "        # '[0:n:h]': list([x, x+w] for x in xs[0 : n : h]),\n",
    "        # '[0:n-w:h]': list([x, x+w] for x in xs[0 : n-w : h]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Same as swift stride(from:through:by:), not stride(from:to:by:)\n",
    "len(range(5210)[0 : 5210 - 512 : 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "pp(librosa.fft_frequencies(sr=22050, n_fft=512).shape)\n",
    "pp(librosa.fft_frequencies(sr=22050, n_fft=512)[250:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "mel_basis = librosa.filters.mel(sr=22050, n_fft=512, n_mels=40)\n",
    "mel_basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = lambda r, c: np.random.rand(r, c)\n",
    "np.dot(M(1,2), M(2,0))\n",
    "np.dot(M(0,2), M(2,3))\n",
    "np.dot(M(1,0), M(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(np.fft.rfft(np.array([1])))\n",
    "np.abs(np.fft.rfft(np.array([1,1])))\n",
    "np.abs(np.fft.rfft(np.array([1,1,1])))\n",
    "np.abs(np.fft.rfft(np.array([1,1,1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "4.613s"
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(5_000_000) * 100\n",
    "X = np.random.rand(3,5)\n",
    "np.save('/tmp/array.npy',  x)\n",
    "np.save('/tmp/matrix.npy', X)\n",
    "np.savez('/tmp/z.npz', x=x, X=X)\n",
    "np.savez_compressed('/tmp/z_compressed.npz', x=x, X=X)\n",
    "display(\n",
    "    np.load('/tmp/array.npy'),\n",
    "    np.load('/tmp/matrix.npy'),\n",
    "    dict(np.load('/tmp/z.npz')),\n",
    "    dict(np.load('/tmp/z_compressed.npz')),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(3,5); X\n",
    "X.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\n",
    "    '/Users/danb/hack/bubo/data/'\n",
    "    'cache/payloads/search_recs-version[8],limit[100],audio_s[10],countries_k[na],com_names_k[ca],num_recs[None]-fb42447/mobile-version[1]/search_recs/models/'\n",
    "    'classifier_.estimators_[97].coef_.npy'\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = dict(\n",
    "    a=1,\n",
    "    b='foo',\n",
    "    c=[1,2,3],\n",
    ")\n",
    "np.save('/tmp/obj.npy', obj)\n",
    "np.load('/tmp/obj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "4.356s"
   },
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "sg.init(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sk.linear_model.LogisticRegressionOneClass\n",
    "X = np.random.rand(5,1500)\n",
    "display(\n",
    "    sg.search.classifier_.predict_proba(X).shape,\n",
    "    sg.search.classifier_.estimators_[0].predict_proba(X).shape,\n",
    "    sg.search.classifier_.estimators_[0].predict_proba(X),\n",
    "    scipy.special.expit(sg.search.classifier_.estimators_[0].decision_function(X)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.search.classifier_.estimators_[0].coef_.shape\n",
    "sg.search.classifier_.estimators_[0].intercept_.shape\n",
    "sk_dir_attrs(sg.search.classifier_)\n",
    "sg.search.classifier_.estimators_[0]\n",
    "sg.search.classifier_.intercept_.shape\n",
    "sg.search.classifier_.estimators_[0].intercept_.shape\n",
    "sk_dirs_attrs(sg.search.classifier_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "import pprint\n",
    "(xc.metadata\n",
    "    [lambda df: pd.notnull(df.species)]\n",
    "    [lambda df: df.country == 'Costa Rica']\n",
    "    .pipe(df_remove_unused_categories).com_name.sort_values()\n",
    "    .pipe(puts, f=lambda s: len(s.unique()))\n",
    "    # .pipe(lambda s:\n",
    "    #     pprint.pprint(s.unique().tolist(), indent=4, width=120, compact=True)\n",
    "    # )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "20.931s"
   },
   "outputs": [],
   "source": [
    "# Q: What kinds of huge recs are out there?\n",
    "#   - A: Holy crap 1.4gb!\n",
    "# Like _compute_search_recs\n",
    "recs = sg.xc_meta\n",
    "# Like recs_featurize_metdata_audio_slice\n",
    "recs = (recs\n",
    "    .pipe(recs_featurize_metadata)\n",
    ")\n",
    "display(\n",
    "    recs.shape,\n",
    "    recs.samples_mb[lambda s: s > 100].shape,\n",
    ")\n",
    "recs.samples_mb[lambda s: s >= 0].plot.hist(bins=100, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "2.212s"
   },
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "load = Load()\n",
    "load.recs_paths(['xc'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "2.69s"
   },
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "load = Load()\n",
    "with cache_control(enabled=False):\n",
    "    display(\n",
    "        load.recs(paths=[('xc', '/Users/danb/hack/bubo/features/data/xc/data/ABAN/12046/audio.mp3')]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "1.951s"
   },
   "outputs": [],
   "source": [
    "from notebooks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_load.load_search_recs.__name__\n",
    "'foo'.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = ['foo', sg_load.load_search_recs]\n",
    "skip = [getattr(f, '__name__', f) for f in skip]\n",
    "skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.0K    server-config.json\n",
    "\n",
    "4.7M    metadata/species.json\n",
    "11M     models/\n",
    "\n",
    "30M     search_recs.sqlite3\n",
    "144M    audio/\n",
    "46M     spectro/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birdgram CA: 2.0G search_recs/ on laptop -> 2.3GB in \"iPhone Storage\"\n",
    "((30 + 144 + 46) * 1024**2 / 1024**3)\n",
    "((30 + 144 + 46) * 1024**2 / 3500 * 69351 / 1024**3)        # 4.26gb <- TOO BIG\n",
    "((30 + 144 + 46) * 1024**2 / 3500 * 69351 * 1/2 / 1024**3)  # 2.13gb\n",
    "((30 + 144 + 46) * 1024**2 / 3500 * 69351 * 2/3 / 1024**3)  # 2.84gb <- Do this\n",
    "((30 + 144 + 46) * 1024**2 / 3500 * 69351 * 3/4 / 1024**3)  # 3.19gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "4.085s"
   },
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "sg.init(None, skip=['load_search_recs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "6.695s"
   },
   "outputs": [],
   "source": [
    "meta = sg_load.load_xc_meta(_nocache=True)['xc_meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(meta\n",
    "    .assign(n=1).groupby('species')['n'].sum().reset_index()\n",
    "    # [:10]\n",
    "    .assign(n=lambda df: np.minimum(200, df.n))\n",
    "    # .n.pipe(lambda s: np.asscalar(s.sum() / len(meta)))\n",
    "    .n.pipe(lambda s: np.asscalar(s.sum()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = (0,3)\n",
    "n = 500\n",
    "range(n)[subset[0]::subset[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "2.79s"
   },
   "outputs": [],
   "source": [
    "from notebooks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/Users/danb/hack/birdgram/mobile/app'\n",
    "json_path = f'{dir}/foo.json'\n",
    "sql_path = f'{dir}/bar.sqlite3'\n",
    "db_url = f'sqlite:///{path}'\n",
    "df = pd.read_json(json_path)\n",
    "with sqla_oneshot_eng_conn_tx(db_url) as conn:\n",
    "    df.to_sql('foo', conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/Users/danb/hack/birdgram/mobile/app/assets/payloads/CA100/search_recs/metadata/species.json'\n",
    "df = pd.read_json(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[lambda df: df.com_name.str.lower().str.contains('vireo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "(xc.metadata\n",
    "    [['id', 'species']]\n",
    "    .rename(columns={'id': 'xc_id'})\n",
    "    .astype({'xc_id': 'str'})\n",
    "    .set_index('xc_id')\n",
    "    ['species']\n",
    "    [:3]\n",
    "    .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "(xc.metadata\n",
    "    [['id', 'species']]\n",
    "    [lambda df: df.isnull()]\n",
    "    [:3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1.5\n",
    "xs = [1,2,3,4]\n",
    "np.linalg.norm(xs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bubo-features (PYTHONSTARTUP)",
   "language": "python",
   "name": "bubo-features (PYTHONSTARTUP)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
