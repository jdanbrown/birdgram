{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "14.554s"
   },
   "outputs": [],
   "source": [
    "# XXX Debug\n",
    "from notebooks import *\n",
    "sg.init(None, skip=[sg_load.load_search_recs])\n",
    "get_search_recs.cache_clear()\n",
    "search_recs = get_search_recs(cache_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "4.626s"
   },
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "sg.init(None, skip=[sg_load.load_search_recs])\n",
    "get_search_recs.cache_clear()\n",
    "kwargss = [\n",
    "    dict(refresh=True),  # Cache miss\n",
    "    dict(),  # Cache hit\n",
    "]\n",
    "search_recss = []\n",
    "for kwargs in kwargss:\n",
    "    print()\n",
    "    print(f'search_recs(**{kwargs})')\n",
    "    search_recs = get_search_recs(**kwargs, cache_type='parquet')\n",
    "    search_recss.append(search_recs)\n",
    "    display(search_recs\n",
    "        [['xc_id', 'feat', 'f_f', 'f_p', 'background', 'background_species']]\n",
    "        [2:3].reset_index(drop=True).T\n",
    "        .pipe(df_assign_first,\n",
    "            size=lambda df: df.T.memory_usage(deep=True),\n",
    "            type=lambda df: df[0].map(lambda x: type(x).__name__),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "7.659s"
   },
   "outputs": [],
   "source": [
    "# TODO Write tests\n",
    "#   - Should roundtrip, should preserve category dtypes, should fail if index present\n",
    "[a, b] = search_recss\n",
    "pd.testing.assert_frame_equal(a, b, check_index_type=True, check_column_type=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XXX Q: Is npy the whole col at once faster than npy each value separately?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = search_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df.feat.map(lambda x: x.shape)[:3],\n",
    "    df.feat[:3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "5.565s"
   },
   "outputs": [],
   "source": [
    "# Slow\n",
    "xs = df.feat.map(np_save_to_bytes)\n",
    "display(\n",
    "    xs.shape,\n",
    "    len(xs),\n",
    "    xs.map(len)[:3],\n",
    "    xs.iloc[0][:100],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "1.672s"
   },
   "outputs": [],
   "source": [
    "# Fast-ish\n",
    "x = np.array(list(df.feat))\n",
    "b = np_save_to_bytes(x)\n",
    "display(\n",
    "    x.shape,\n",
    "    len(b),\n",
    "    b[:100],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "13.232s"
   },
   "outputs": [],
   "source": [
    "# Slow\n",
    "(df\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        f'{k}.{i}': df[k].str[i]\n",
    "        for k, n in {'feat': 1500}.items()\n",
    "        for i in tqdm(range(n))\n",
    "    }))\n",
    "    [['xc_id', 'feat.0', 'feat.1', 'feat.2']]\n",
    "    [:3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "3.254s"
   },
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "# np.array(big_list) is fast-ish\n",
    "x = np.array(list(df.feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "# DF(big_array) is fast\n",
    "DF(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[:10]\n",
    "path = '/tmp/x.feather'\n",
    "# df0.to_feather(path)  # XXX ArrowNotImplementedError: list<item: double>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[:10]\n",
    "path = '/tmp/x.pyarrow'\n",
    "df0.to_parquet(path, engine='pyarrow')\n",
    "out = pd.read_parquet(path, engine='pyarrow')\n",
    "pd.testing.assert_frame_equal(\n",
    "    df0.pipe(df_cat_to_str),  # FIXME categories\n",
    "    out.reset_index(drop=True),  # Drop Int64Index -> RangeIndex\n",
    "    check_index_type=True, check_column_type=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "23.16s"
   },
   "outputs": [],
   "source": [
    "df0 = df\n",
    "path = '/tmp/x.pyarrow'\n",
    "%time df0.to_parquet(path, engine='pyarrow')         # 11.7s\n",
    "%time out = pd.read_parquet(path, engine='pyarrow')  # 2.4s\n",
    "pd.testing.assert_frame_equal(\n",
    "    df0.pipe(df_cat_to_str),  # FIXME categories\n",
    "    out.reset_index(drop=True),  # Drop Int64Index -> RangeIndex\n",
    "    check_index_type=True, check_column_type=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q: What if we go wide?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "4.132s"
   },
   "outputs": [],
   "source": [
    "feat_cols = ['feat', 'f_f', 'f_p']\n",
    "wide = (df\n",
    "    # [:3]\n",
    "    .pipe(lambda df: (\n",
    "        pd.concat(axis=1, objs=[\n",
    "            df.drop(columns=['feat', 'f_f', 'f_p']),\n",
    "            *[\n",
    "                DF(np.array(list(df[c]))).rename(columns=lambda i: f'{c}.{i}')\n",
    "                for c in feat_cols\n",
    "            ],\n",
    "        ])\n",
    "    ))\n",
    ")\n",
    "wide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "10.209s"
   },
   "outputs": [],
   "source": [
    "# df0 = wide[:10]\n",
    "df0 = wide\n",
    "path = '/tmp/wide.parquet'\n",
    "cat_cols = [c for c in df0 if df0[c].dtype.name == 'category']\n",
    "%time df0.to_parquet(path, engine='fastparquet', compression='uncompressed')\n",
    "%time out = pd.read_parquet(path, engine='fastparquet')\n",
    "pd.testing.assert_frame_equal(\n",
    "    df0,\n",
    "    out.pipe(df_transform_cats, ordered=True, col_names=cat_cols),  # FIXME categories come out as ordered=False\n",
    "    check_index_type=True, check_column_type=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "2.54s"
   },
   "outputs": [],
   "source": [
    "(out\n",
    "    .pipe(df_inspect, lambda df: (df.shape,))\n",
    "    .assign(**{k: list(out.filter(regex=f'^{k}\\.').values) for k in feat_cols})\n",
    "    .pipe(df_inspect, lambda df: (df.shape,))\n",
    "    [lambda df: [c for c in df if not any(c.startswith(f'{k}.') for k in feat_cols)]]\n",
    "    .pipe(df_inspect, lambda df: (df.shape,))\n",
    "    # .memory_usage(deep=True).sort_index()\n",
    "    [:1].T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "8.628s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(35231, 58)"
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "data": {
      "text/plain": "(35231, 3386)"
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "data": {
      "text/plain": "(35231, 3386)"
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    }
   ],
   "source": [
    "display(\n",
    "    df.shape,\n",
    "    wide.shape,\n",
    "    wide.values.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div style=\"white-space: pre\">feat          426436024\nid             24629926\npath           24629926\nbasename       19019126\nremarks        18617184\nplace          12394483\nlocality       10044112\nlicense         9892276\ndownload        8464461\nplace_only      8131687</div>",
      "text/plain": "feat          426436024\nid             24629926\npath           24629926\nbasename       19019126\nremarks        18617184\nplace          12394483\nlocality       10044112\nlicense         9892276\ndownload        8464461\nplace_only      8131687\ndtype: int64"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE Not always correct...\n",
    "df.memory_usage(deep=True).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "6.244s"
   },
   "outputs": [],
   "source": [
    "# NOTE np.save bloats non-numeric arrays -- e.g remarks 1.8m -> 500m!\n",
    "(df\n",
    "    # [:10]\n",
    "    .pipe(lambda df: (\n",
    "        [np.save(f'/tmp/df-{k}.npy', np.array(list(df[k]))) for k in tqdm(df.columns)],  #\n",
    "    ))\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "4.394s"
   },
   "outputs": [],
   "source": [
    "# Correct results from .parquet the non-array cols and .npy the array cols...\n",
    "(df\n",
    "    # [:10]\n",
    "    .pipe(lambda df: (\n",
    "        [df[[k]].to_parquet(f'/tmp/df-{k}.parquet') for k in tqdm(df.columns) if k not in feat_cols],\n",
    "        [np.save(f'/tmp/df-{k}.npy', np.array(list(df[k]))) for k in tqdm(df.columns) if k in feat_cols],\n",
    "    ))\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ensure_dir('/tmp/save-1')\n",
    "feat_cols = ['feat', 'f_f', 'f_p']\n",
    "measure = lambda desc, f: timed_print(f, print=lambda x: print(f'{x} {desc}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO TODO Save/load separate files: non_feats.parquet + feats.npy\n",
    "- Finally a promising approach\n",
    "- A little more complexity to manage, but not much\n",
    "- Great! 1.1s load, 3.0 save\n",
    "- Solution -> notebooks/api_dev_search_recs_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "4.837s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "35231"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:00.764] non_feats"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:01.686] feat"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:00.638] f_f"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:00.331] f_p"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:03.426] save"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    }
   ],
   "source": [
    "def save(df):\n",
    "    print(len(df))\n",
    "    df_require_index_is_trivial(df)\n",
    "    measure('non_feats', lambda: (df\n",
    "        [[k for k in df if k not in feat_cols]]\n",
    "        .to_parquet(f'{path}/non_feats.parquet', engine='fastparquet', compression='uncompressed')\n",
    "    ))\n",
    "    [measure(k, lambda: np.save(f'{path}/feat-{k}.npy', np.array(list(df[k])))) for k in df.columns if k in feat_cols]\n",
    "    return df\n",
    "saved = measure('save', lambda: save(search_recs\n",
    "    # [:10]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "2.926s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:00.393] non_feats"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:00.252] feat"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:00.159] f_f"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:00.121] f_p"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:00.360] out"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[00:01.387] total"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "data": {
      "text/plain": "(35231, 58)"
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "data": {
      "text/plain": "(35231, 58)"
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    }
   ],
   "source": [
    "def load():\n",
    "    non_feats = measure('non_feats', lambda: (\n",
    "        pd.read_parquet(f'{path}/non_feats.parquet', engine='fastparquet')\n",
    "    ))\n",
    "    feats = {k: measure(k, lambda: np.load(f'{path}/feat-{k}.npy')) for k in feat_cols}\n",
    "    df = measure('out', lambda: non_feats.assign(**{k: list(x) for k, x in feats.items()}))\n",
    "    assert (df.index == pd.RangeIndex(len(df))).all()\n",
    "    df = df.reset_index(drop=True)  # Drop Int64Index, restore trivial RangeIndex\n",
    "    return df\n",
    "loaded = measure('total', load)\n",
    "display(\n",
    "    saved.shape,\n",
    "    loaded.shape,\n",
    "    # loaded[:1].T,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "8.783s"
   },
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(\n",
    "    (saved\n",
    "        .pipe(df_reorder_cols, last=feat_cols)\n",
    "    ),\n",
    "    (loaded\n",
    "        # TODO TODO Manually save df.columns to restore col order\n",
    "        # TODO TODO Manually save df.dtypes to restore categories (and dtypes generally)\n",
    "        #   - Then we win! (fingers crossed...)\n",
    "        .pipe(df_reorder_cols, last=feat_cols)\n",
    "        .pipe(df_transform_cats, ordered=True, col_names=[k for k in loaded if loaded[k].dtype.name == 'category'])\n",
    "    ),\n",
    "    check_index_type=True,\n",
    "    check_column_type=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bubo-features (PYTHONSTARTUP)",
   "language": "python",
   "name": "bubo-features (PYTHONSTARTUP)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
