{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from potoo.plot import *\n",
    "from potoo.util import *\n",
    "import sklearn\n",
    "\n",
    "from cache import *\n",
    "from datasets import *\n",
    "from features import *\n",
    "from load import *\n",
    "from sp14.model import *\n",
    "from util import *\n",
    "\n",
    "figsize('inline_short');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[\n  '/Users/danb/hack/bubo/data/mlsp-2013/light_data',\n  '/Users/danb/hack/bubo/data/mlsp-2013/mlsp13birdchallenge_documentation.pdf',\n  '/Users/danb/hack/bubo/data/mlsp-2013/mlsp_contest_dataset',\n  '/Users/danb/hack/bubo/data/mlsp-2013/README.txt',\n]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(f'{data_dir}/mlsp-2013/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(f'{data_dir}/mlsp-2013/light_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(f'{data_dir}/mlsp-2013/mlsp_contest_dataset/essential_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boring\n",
    "# pd.read_csv(f'{data_dir}/mlsp-2013/mlsp_contest_dataset/essential_data/CVfolds_2.txt')[:50]\n",
    "\n",
    "# Interesting\n",
    "rec_id_to_filename_df = pd.read_csv(f'{data_dir}/mlsp-2013/mlsp_contest_dataset/essential_data/rec_id2filename.txt')\n",
    "sample_submission_df = pd.read_csv(f'{data_dir}/mlsp-2013/mlsp_contest_dataset/essential_data/sample_submission.csv')\n",
    "species_df = pd.read_csv(f'{data_dir}/mlsp-2013/mlsp_contest_dataset/essential_data/species_list.txt')\n",
    "\n",
    "# This one has variable numbers of columns, so parse it manually\n",
    "with open(f'{data_dir}/mlsp-2013/mlsp_contest_dataset/essential_data/rec_labels_test_hidden.txt') as f:\n",
    "    rec_labels_test_hidden_df = (\n",
    "        pd.DataFrame(line.rstrip().split(',', 1) for line in f.readlines())\n",
    "        .T.set_index(0).T  # Pull first row into df col names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    species_df.shape,\n",
    "    species_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    rec_id_to_filename_df.shape,\n",
    "    rec_id_to_filename_df[:10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    sample_submission_df.shape,\n",
    "    sample_submission_df[:10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test examples are '[labels]' = '?'\n",
    "display(\n",
    "    rec_labels_test_hidden_df.shape,\n",
    "    rec_labels_test_hidden_df[:10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train vs. test\n",
    "train_labels_df = rec_labels_test_hidden_df[lambda df: df['[labels]'] != '?']\n",
    "test_labels_df = rec_labels_test_hidden_df[lambda df: df['[labels]'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    test_labels_df.shape,\n",
    "    test_labels_df[:10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    train_labels_df.shape,\n",
    "    train_labels_df[:10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many train vs. test recordings?\n",
    "(rec_labels_test_hidden_df\n",
    "    .assign(group=lambda df: df['[labels]'].map(lambda x: 'test' if x == '?' else 'train'))\n",
    "    .assign(n=1).groupby('group')['n'].count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_labels_df\n",
    "    ['[labels]']\n",
    "    .fillna('')\n",
    "    .map(lambda s: [int(x) for x in s.split(',') if x != ''])\n",
    "    .map(lambda class_ids: len(class_ids))\n",
    "    .pipe(gghist)\n",
    "    + xlab('num species in same recording')\n",
    "    + ylab('num recordings')\n",
    "    + ggtitle('How many species per training recording?')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_labels_df\n",
    "    .fillna({'[labels]': '-1'})\n",
    "    .astype({'rec_id': 'int'})\n",
    "    .set_index('rec_id')['[labels]']\n",
    "    .fillna('')\n",
    "    .map(lambda s: [int(x) for x in s.split(',') if x != ''])\n",
    "    .apply(pd.Series).unstack()  # flatmap\n",
    "    .reset_index(level=0, drop=True)  # Drop 'level' index\n",
    "    .sort_index().reset_index()  # Sort and reset 'rec_id' index\n",
    "    .rename(columns={0: 'class_id'})\n",
    "    .dropna()\n",
    "    .merge(species_df, how='left', on='class_id').drop(columns=['class_id'])\n",
    "    .fillna({'code': 'none', 'species': 'none'})\n",
    "    .pipe(ggplot, aes(x='code'))\n",
    "    + geom_bar()\n",
    "    + coord_flip()\n",
    "    + xlab('species')\n",
    "    + ylab('num recordings')\n",
    "    + ggtitle('How many training recordings per species? (multiple species per recording)')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_paths = load_recs_paths(['mlsp-2013'])\n",
    "display(\n",
    "    recs_paths.shape,\n",
    "    recs_paths.groupby('dataset').head(5),\n",
    "    recs_paths.dataset.value_counts(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = load_recs_data(\n",
    "    (recs_paths\n",
    "        # .sample(1000)  # For faster dev\n",
    "    ),\n",
    "    # FIXME pickling AudioSegment's across processes makes this (1) slow and (2) super-linearly slow\n",
    "    #   - TODO We want 'processes' par for converting audio to std .wav format and 'threads' par for loading from std\n",
    "    #     .wav, so split the convert (metadata_only=True) + load (metadata_only=False) steps to separate these concerns\n",
    "    # metadata_only=True, dask_opts=dict(scheduler='processes'),\n",
    "    metadata_only=False, dask_opts=dict(scheduler='threads'),\n",
    ")\n",
    "display(\n",
    "    recs.shape,\n",
    "    recs[:20],\n",
    "    recs[:1].T,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats\n",
    "(recs\n",
    "    .fillna('')\n",
    "    .assign(\n",
    "        n=1,\n",
    "        duration_h=lambda df: df.duration_s / 3600,\n",
    "        samples_gb=lambda df: df.samples_mb / 1024,\n",
    "    )\n",
    "    .groupby([\n",
    "        'dataset',\n",
    "        'species',\n",
    "    ])\n",
    "    [['n', 'duration_h', 'samples_gb', 'samples_n']]\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO What did 'XXXX' vs. 'none' mean here? [see datasets.metadata_from_audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_multi = (recs\n",
    "    .pipe(df_flatmap_list_col, 'species', lambda s: s.str.split(','))\n",
    ")\n",
    "display(\n",
    "    recs_multi.shape,\n",
    "    recs_multi[:20]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats\n",
    "(recs_multi\n",
    "    .fillna('')\n",
    "    .assign(\n",
    "        n=1,\n",
    "        duration_h=lambda df: df.duration_s / 3600,\n",
    "        samples_gb=lambda df: df.samples_mb / 1024,\n",
    "    )\n",
    "    .groupby([\n",
    "        'dataset',\n",
    "        'species',\n",
    "    ])\n",
    "    [['n', 'duration_h', 'samples_gb', 'samples_n']]\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   - [ ] Inspect random spectros: how much non-bird time? how much noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_test = (recs\n",
    "    [lambda df: ~df.species.isin(['XXXX', 'none'])]\n",
    "    [lambda df: df.species.str.split(',').str.len() == 1]\n",
    ")\n",
    "display(\n",
    "    recs_test.shape,\n",
    "    recs_test[:10],\n",
    "    (recs_test\n",
    "        .assign(n=1)\n",
    "        .groupby(['dataset', 'species'])\n",
    "        ['n'].sum()\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectros\n",
    "model = Model(verbose_config=False)\n",
    "display(dict(model.config))\n",
    "spectros = Model._spectros(df_rows(recs_test), **model.config.patch_config.spectro_config)\n",
    "display(len(spectros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with with_figsize(width=24, aspect_ratio=1/16):\n",
    "    for spectro in spectros[:10]:\n",
    "        spectro.plot(show_audio=False, fancy=False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sp14.model import *\n",
    "for i, config in enumerate([\n",
    "    # Dict(n=None, proj_skm_config=dict(k=40, normalize=False, standardize=False, pca_whiten=True, do_pca=True)),  # Full (slow)\n",
    "    Dict(n=50, proj_skm_config=dict(k=40, normalize=False, standardize=False, pca_whiten=True, do_pca=True)),  # Defaults\n",
    "    Dict(n=50, proj_skm_config=dict(k=40, normalize=False, standardize=False, pca_whiten=False, do_pca=False)),\n",
    "    Dict(n=50, proj_skm_config=dict(k=40, normalize=True, standardize=False, pca_whiten=False, do_pca=False)),\n",
    "    Dict(n=50, proj_skm_config=dict(k=40, normalize=False, standardize=True, pca_whiten=False, do_pca=False)),\n",
    "    Dict(n=50, proj_skm_config=dict(k=40, normalize=True, standardize=True, pca_whiten=False, do_pca=False)),\n",
    "    Dict(n=50, proj_skm_config=dict(k=40, normalize=True, standardize=True, pca_whiten=True, do_pca=True)),\n",
    "]):\n",
    "    print(f'\\n\\ni[{i}] config[{config}]\\n\\n')\n",
    "    model = Model(\n",
    "        verbose_config=False,\n",
    "        proj_skm_config=config.proj_skm_config,\n",
    "    )\n",
    "    # model.proj_skm_.args  # [Can't run until after model.fit_proj, below]\n",
    "\n",
    "    # %%\n",
    "    recs_test_n = (recs_test\n",
    "        .pipe(sklearn.utils.shuffle, random_state=0)\n",
    "        [:config.n]\n",
    "    )\n",
    "\n",
    "    # %%time\n",
    "    # One skm example per rec (not one per recs_multi)\n",
    "    #   - recs: 248s, 645 recs, 552765 patches\n",
    "    #   - recs[:100]: 30s, 100 recs, 85700 patches\n",
    "    #   - recs[:10]: (fast), 10 recs, 8570 patches\n",
    "    model.fit_proj(recs_test_n)\n",
    "\n",
    "    # %%\n",
    "    # # TODO\n",
    "    # #   - [ ] Inspect learned centroid patches: do they look plausible?\n",
    "\n",
    "    # %%\n",
    "    # # skm.transform(X)\n",
    "    # # = (skm._pca_transform(X).T @ skm.D).T\n",
    "    # # = (skm.pca.transform(X.T) @ skm.D).T\n",
    "    # # = (X.T @ skm.pca.components_.T @ skm.D).T\n",
    "    # # = skm.D.T @ skm.pca.components_ @ X\n",
    "    # #\n",
    "    # # skm.transform\n",
    "    # # = skm.D.T @ skm.pca.components_\n",
    "\n",
    "    # %%\n",
    "    skm = model.proj_skm_\n",
    "    skm_transform = (skm.D.T @ skm.pca.components_).T\n",
    "    # display(\n",
    "    #     skm.D.shape,\n",
    "    #     skm.D,\n",
    "    #     skm.pca.components_.shape,\n",
    "    #     skm.pca.components_,\n",
    "    #     skm_transform.shape,\n",
    "    #     skm_transform,\n",
    "    # )\n",
    "\n",
    "    # %%\n",
    "    # plt.imshow(skm.D, origin='lower')\n",
    "\n",
    "    # %%\n",
    "    # plt.imshow(skm_transform, origin='lower')\n",
    "\n",
    "    # %%\n",
    "    (fp, k) = skm_transform.shape\n",
    "    p = 4\n",
    "    f = fp // p\n",
    "    x = np.array([\n",
    "        skm_transform[i*f:(i+1)*f, j]\n",
    "        for i in range(p)\n",
    "        for j in range(k)\n",
    "    ]).T\n",
    "    # display(skm_transform.shape)\n",
    "    # display(x.shape)\n",
    "    plt.pcolormesh(x[:, :160])\n",
    "    plt.show()\n",
    "\n",
    "    # # %%\n",
    "    # model.fit_class(recs_test_n)\n",
    "    # display(\n",
    "    #     model.test(recs_test_n, 'classes'),\n",
    "    #     model.test(recs_test_n, 'kneighbors'),\n",
    "    # )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bubo-features (PYTHONSTARTUP)",
   "language": "python",
   "name": "bubo-features (PYTHONSTARTUP)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
