{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "- Maintain separate payloads for api vs. mobile\n",
    "    - Faster to read/write .parquet + .npy, but only api can use those\n",
    "    - Mobile needs to use .sqlite + files (.png, .mp4), but it's slower for both read and write\n",
    "- TODO Still more room to compress mobile payloads\n",
    "    - 71% of payload: audio\n",
    "        - Can be cut in ~half if we can drop 32k -> 16k (maybe with aac_he?)\n",
    "            - Android supports HE-AACv2: https://developer.android.com/guide/topics/media/media-formats\n",
    "            - But ios doesn't? https://apple.co/2NORQHB\n",
    "        - Payload 1.98g -> ~1.28g -- âœ… ~35% of payload\n",
    "    - 21% of payload: spectro\n",
    "        - Not much excess: maybe ~5% of spectros (see notebooks/spectro_img_encode)\n",
    "        - Payload 1.98g -> ~1.96g -- âŒ ~1% of payload\n",
    "    - 5.9% of payload: f_preds_* sqlite cols (n_sp=331)\n",
    "        - (Based on: 119m = 164m with - 45m without)\n",
    "        - No float32 in sqlite, only float64 [â“ Unless we get clever and pack into int32/int16, or blob...]\n",
    "            - [e.g. blob: https://github.com/SeanTater/sqlite3-extras]\n",
    "        - Can pca compress, but can't achieve more than a few % of payload\n",
    "        - Payload 1.98g -> ~1.98g with n_components=331 -- min ~0% of payload\n",
    "        - Payload 1.98g -> ~1.93g with n_components=150 --  ðŸ”¶ ~3% of payload\n",
    "        - Payload 1.98g -> ~1.90g with n_components=100 --  ðŸ”¶ ~4% of payload\n",
    "        - Payload 1.98g -> ~1.86g with n_components=10  --  ðŸ”¶ ~6% of payload\n",
    "        - Payload 1.98g -> ~1.86g with n_components=0   -- max ~6% of payload\n",
    "    - 2.2% of payload: rest of sqlite cols\n",
    "        - Max ~2% of payload -- âŒ low ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "10.888s"
   },
   "outputs": [],
   "source": [
    "from notebooks import *\n",
    "sg.init(None, skip=[sg_load.load_search_recs])\n",
    "get_search_recs.cache_clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perf notes\n",
    "\n",
    "Before\n",
    "- Cold cache (warm pagecache but cold python proc)\n",
    "```\n",
    "search_recs(**{'cache_type': 'hybrid'})\n",
    "...\n",
    "DEBUG    [12:58:26.994] [37904] 119 payloads/df_cache_hybrid: Hit [start]\n",
    "DEBUG    [12:58:27.001] [37904] 129 payloads/df_cache_hybrid: Hit: Reading non_feats.parquet (1.8 GB)\n",
    "INFO     [12:58:32.028] [37904] 136 payloads/df_cache_hybrid: Hit: Read non_feats.parquet (1.8 GB)\n",
    "DEBUG    [12:58:32.040] [37904] 141 payloads/df_cache_hybrid: Hit: Reading feat-f_preds.npy (46.6 MB)\n",
    "INFO     [12:58:32.077] [37904] 143 payloads/df_cache_hybrid: Hit: Read feat-f_preds.npy: float32 (46.6 MB)\n",
    "DEBUG    [12:58:32.084] [37904] 141 payloads/df_cache_hybrid: Hit: Reading feat-feat.npy (211.4 MB)\n",
    "INFO     [12:58:32.211] [37904] 143 payloads/df_cache_hybrid: Hit: Read feat-feat.npy: float32 (211.4 MB)\n",
    "INFO     [12:58:32.218] [37904] 147 payloads/df_cache_hybrid: Hit: Join non_feats + feats\n",
    "INFO     [12:58:32.469] [37904] 155 payloads/df_cache_hybrid: Hit [5.475s]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "11.785s"
   },
   "outputs": [],
   "source": [
    "# Fail if too few recs are downloaded (easy way to waste a bunch of training time!)\n",
    "sg_load.load_xc_meta(_nocache=True,\n",
    "    fail_on_low_download_frac=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "time": "52.317s"
   },
   "outputs": [],
   "source": [
    "with ExitStack() as stack:\n",
    "    # stack.enter_context(cache_control(refresh=True))  # XXX Debug\n",
    "    log_levels({\n",
    "        'payloads': 'INFO',\n",
    "        # 'payloads': 'DEBUG',\n",
    "    })\n",
    "    kwargss = [\n",
    "        # dict(cache_type='hybrid', refresh=True),  # Simulate cache miss [XXX Debug]\n",
    "        dict(cache_type='hybrid'),                  # Allow cache hit\n",
    "    ]\n",
    "    search_recss = []\n",
    "    for i, kwargs in enumerate(kwargss):\n",
    "        if i > 0: print()\n",
    "        print(f'search_recs(**{kwargs})')\n",
    "        get_search_recs.cache_clear()\n",
    "        search_recs = get_search_recs(**kwargs,\n",
    "            write_mobile_payload=True,\n",
    "            plot_sizes=True,\n",
    "        )\n",
    "        search_recss.append(search_recs)\n",
    "        display(search_recs\n",
    "            [['xc_id', 'feat', 'f_preds', 'background', 'background_species']]\n",
    "            [2:3].reset_index(drop=True).T\n",
    "            .pipe(df_assign_first,\n",
    "                size=lambda df: df.T.memory_usage(deep=True),\n",
    "                type=lambda df: df[0].map(lambda x: type(x).__name__),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "skip": true
   },
   "outputs": [],
   "source": [
    "# TODO Turn this into unit tests\n",
    "#   - Should roundtrip, should preserve category dtypes, should fail if index present\n",
    "assert len(search_recss) == 2, \"Test requires both 'cache hit' + 'cache miss' to be uncommented (above)\"\n",
    "[a, b] = search_recss\n",
    "pd.testing.assert_frame_equal(a, b, check_column_type=True,\n",
    "    check_index_type=False,  # Allow Int64Index vs. RangeIndex\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
