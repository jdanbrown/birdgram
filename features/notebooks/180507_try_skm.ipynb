{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize('inline_short')\n",
    "\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "from sp14.skm import SKM\n",
    "from sp14.skm_util import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "#   - skm expects data of the shape (freqs, patches)\n",
    "npoints = 200\n",
    "X_train = dict(\n",
    "    a=np.array(polar_to_cart(\n",
    "        r=5 + np.random.normal(size=npoints, scale=1),\n",
    "        theta=np.pi/4.0 + np.random.normal(size=npoints, scale=np.pi/8.0),\n",
    "    )),\n",
    "    b=np.array(polar_to_cart(\n",
    "        r=7 + np.random.normal(size=npoints, scale=2),\n",
    "        theta=-np.pi/4.0 + np.random.normal(size=npoints, scale=np.pi/32.0),\n",
    "    )),\n",
    "    c=np.array(polar_to_cart(\n",
    "        r=5 + np.random.normal(size=npoints, scale=1),\n",
    "        theta=5/4.0  * np.pi + np.random.normal(size=npoints, scale=np.pi/8.0),\n",
    "    )),\n",
    ")\n",
    "display(\n",
    "    X_train['a'].shape,\n",
    "    X_train['b'].shape,\n",
    "    X_train['c'].shape,\n",
    ")\n",
    "plt.plot(X_train['a'][0], X_train['a'][1], 'b.')\n",
    "plt.plot(X_train['b'][0], X_train['b'][1], 'r.')\n",
    "plt.plot(X_train['c'][0], X_train['c'][1], 'g.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one unlabeled dataset and shuffle\n",
    "X_train_nolab = np.concatenate((X_train['a'].T, X_train['b'].T, X_train['c'].T))\n",
    "np.random.shuffle(X_train_nolab)\n",
    "X_train_nolab = X_train_nolab.T\n",
    "display(X_train_nolab.shape)\n",
    "plt.plot(X_train_nolab[0,:], X_train_nolab[1,:], 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn features\n",
    "- Fit SKM centroids from the unlabeled version of the training data\n",
    "- This produces an over-complete basis that we will use for the classification feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skm = SKM(\n",
    "    k=10,\n",
    "    # variance_explained=0.99,\n",
    "    # max_epocs=100,\n",
    "    # assignment_change_eps=0.01,\n",
    "    # standardize=False,\n",
    "    # normalize=False,\n",
    "    # do_pca=True,\n",
    "    # pca_whiten=True,\n",
    "    # visualize=False,\n",
    ")\n",
    "\n",
    "%time skm.fit(X_train_nolab)\n",
    "display(\n",
    "    'Fitted centroids:',\n",
    "    skm.D.shape,\n",
    "    skm.D,\n",
    "    'Fitted whitening PCA:',\n",
    "    skm.pca,\n",
    "    skm.pca.components_,\n",
    ")\n",
    "\n",
    "skm_visualize_clusters(skm, X_train_nolab)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the PCA whitening that SKM just did\n",
    "- Whiten = decorrelate + standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the whitening from skm.fit\n",
    "X_train_nolab_white = skm.pca.transform(X_train_nolab.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The whitened feature cov matrix should be ~I\n",
    "for subplot, X in [\n",
    "    (121, np.cov(X_train_nolab)),\n",
    "    (122, np.cov(X_train_nolab_white)),\n",
    "]:\n",
    "    display(X)\n",
    "    plt.subplot(subplot)\n",
    "    plt.pcolormesh(X, cmap=mpl.cm.Greys_r)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The whitened data should have \"balanced\" feature dimensions\n",
    "plt.subplot(121); plt.plot(X_train_nolab[0,:], X_train_nolab[1,:], 'k.')\n",
    "plt.subplot(122); plt.plot(X_train_nolab_white[0,:], X_train_nolab_white[1,:], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project test data onto the fitted skm centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some test data\n",
    "X_test = np.array(polar_to_cart(\n",
    "    r=5 + np.random.normal(size=200, scale=1),\n",
    "    theta=np.pi/4.0 + np.random.normal(size=npoints, scale=np.pi/8.0),\n",
    "))\n",
    "display(X_test.shape)\n",
    "plt.plot(X_test[0], X_test[1], 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the test data using skm.transform, which:\n",
    "#   - PCA whitens the test data, using the learned PCA from the (unlabeled) training data\n",
    "#   - Projects the test data to the learned dictionary skm.D (i.e. the cluster centroids)\n",
    "X_test_proj = skm.transform(X_test)\n",
    "display(\n",
    "    X_test.shape,  # n_freqs x n_patches\n",
    "    X_test_proj.shape,  # n_centroids x n_patches\n",
    ")\n",
    "plt.subplot(121); plt.plot(X_test[0], X_test[1], 'b.')  # All 2 freq dims of the test data\n",
    "plt.subplot(122); plt.plot(X_test_proj[0], X_test_proj[1], 'b.')  # Just the first two dims of X_test_proj (= first 2 PCs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the patches (= time = samples) dimension for each cluster centroid (= over-completion of freqs)\n",
    "#   - Reduces dimensionality\n",
    "#   - Forgets time structure (we don't need to mess with alignment -- but we do lose sequential structure of songs)\n",
    "\n",
    "def agg_over_time(X: 'np.ndarray[n_centroids, n_patches]', aggs: List[str]) -> 'pd.DataFrame[n_centroids, n_aggs]':\n",
    "    '''\n",
    "    Aggregate each centroid row X[i,:] using each agg function ('mean', 'std', 'min', 'max', etc.)\n",
    "    '''\n",
    "    return pd.DataFrame(OrderedDict({\n",
    "        agg: {\n",
    "            'mean':     lambda X: np.mean(X, axis=1),\n",
    "            'std':      lambda X: np.std(X, axis=1),\n",
    "            'min':      lambda X: np.min(X, axis=1),\n",
    "            'max':      lambda X: np.max(X, axis=1),\n",
    "            'median':   lambda X: np.median(X, axis=1),\n",
    "            'skewness': lambda X: scipy.stats.skew(X, axis=1),\n",
    "            'kurtosis': lambda X: scipy.stats.kurtosis(X, axis=1),\n",
    "            'dmean':    lambda X: np.mean(np.diff(X, axis=1), axis=1),\n",
    "            'dstd':     lambda X: np.std(np.diff(X, axis=1), axis=1),\n",
    "            'dmean2':   lambda X: np.mean(np.diff(np.diff(X, axis=1), axis=1), axis=1),\n",
    "            'dstd2':    lambda X: np.std(np.diff(np.diff(X, axis=1), axis=1), axis=1),\n",
    "        }[agg](X)\n",
    "        for agg in aggs\n",
    "    }))\n",
    "\n",
    "# A friendly df of the aggregated centroid features [make tidy?]\n",
    "#   - (n_centroids, n_patches) -> (n_centroids, n_aggs)\n",
    "X_test_proj_agg_df = agg_over_time(X_test_proj, [\n",
    "    'mean',\n",
    "    'std',\n",
    "    'max',\n",
    "])\n",
    "\n",
    "# The raw feature vector, which should finally be amenable to vanilla classification\n",
    "#   - (n_centroids, n_patches) -> (n_centroids * n_aggs,)\n",
    "X_test_proj_agg_flat = X_test_proj_agg_df.T.values.flatten()\n",
    "\n",
    "display(\n",
    "    X_test_proj.shape,\n",
    "    X_test_proj_agg_df.shape,\n",
    "    X_test_proj_agg_df,\n",
    "    X_test_proj_agg_flat.shape,\n",
    "    X_test_proj_agg_flat,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
