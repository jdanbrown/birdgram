{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize('inline_short')\n",
    "\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "from skm import SKM\n",
    "\n",
    "from features.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "#   - skm expects data of the shape (freqs, patches)\n",
    "npoints = 200\n",
    "X_train = dict(\n",
    "    a=np.array(polar_to_cart(\n",
    "        r=5 + np.random.normal(size=npoints, scale=1),\n",
    "        theta=np.pi/4.0 + np.random.normal(size=npoints, scale=np.pi/8.0),\n",
    "    )),\n",
    "    b=np.array(polar_to_cart(\n",
    "        r=7 + np.random.normal(size=npoints, scale=2),\n",
    "        theta=-np.pi/4.0 + np.random.normal(size=npoints, scale=np.pi/32.0),\n",
    "    )),\n",
    "    c=np.array(polar_to_cart(\n",
    "        r=5 + np.random.normal(size=npoints, scale=1),\n",
    "        theta=5/4.0  * np.pi + np.random.normal(size=npoints, scale=np.pi/8.0),\n",
    "    )),\n",
    ")\n",
    "display(\n",
    "    X_train['a'].shape,\n",
    "    X_train['b'].shape,\n",
    "    X_train['c'].shape,\n",
    ")\n",
    "plt.plot(X_train['a'][0], X_train['a'][1], 'b.')\n",
    "plt.plot(X_train['b'][0], X_train['b'][1], 'r.')\n",
    "plt.plot(X_train['c'][0], X_train['c'][1], 'g.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one unlabeled dataset and shuffle\n",
    "X_train_nolab = np.concatenate((X_train['a'].T, X_train['b'].T, X_train['c'].T))\n",
    "np.random.shuffle(X_train_nolab)\n",
    "X_train_nolab = X_train_nolab.T\n",
    "display(X_train_nolab.shape)\n",
    "plt.plot(X_train_nolab[0,:], X_train_nolab[1,:], 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn features\n",
    "- Fit SKM centroids from the unlabeled version of the training data\n",
    "- This produces an over-complete basis that we will use for the classification feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skm = SKM(\n",
    "    k=10,\n",
    "    # variance_explained=0.99,\n",
    "    # max_epocs=100,\n",
    "    # assignment_change_eps=0.01,\n",
    "    # standardize=False,\n",
    "    # normalize=False,\n",
    "    # do_pca=True,\n",
    "    # pca_whiten=True,\n",
    "    # visualize=False,\n",
    ")\n",
    "\n",
    "%time skm.fit(X_train_nolab)\n",
    "display(\n",
    "    'Fitted centroids:',\n",
    "    skm.D.shape,\n",
    "    skm.D,\n",
    "    'Fitted whitening PCA:',\n",
    "    skm.pca,\n",
    "    skm.pca.components_,\n",
    ")\n",
    "\n",
    "skm_visualize_clusters(skm, X_train_nolab)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the PCA whitening that SKM just did\n",
    "- Whiten = decorrelate + standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the whitening from skm.fit\n",
    "X_train_nolab_white = skm.pca.transform(X_train_nolab.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The whitened feature cov matrix should be ~I\n",
    "for subplot, X in [\n",
    "    (121, np.cov(X_train_nolab)),\n",
    "    (122, np.cov(X_train_nolab_white)),\n",
    "]:\n",
    "    display(X)\n",
    "    plt.subplot(subplot)\n",
    "    plt.pcolormesh(X, cmap=mpl.cm.Greys_r)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The whitened data should have \"balanced\" feature dimensions\n",
    "plt.subplot(121); plt.plot(X_train_nolab[0,:], X_train_nolab[1,:], 'k.')\n",
    "plt.subplot(122); plt.plot(X_train_nolab_white[0,:], X_train_nolab_white[1,:], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project test data onto the fitted skm centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some test data\n",
    "X_test = np.array(polar_to_cart(\n",
    "    r=5 + np.random.normal(size=200, scale=1),\n",
    "    theta=np.pi/4.0 + np.random.normal(size=npoints, scale=np.pi/8.0),\n",
    "))\n",
    "display(X_test.shape)\n",
    "plt.plot(X_test[0], X_test[1], 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the test data using skm.transform, which:\n",
    "#   - PCA whitens the test data, using the learned PCA from the (unlabeled) training data\n",
    "#   - Projects the test data to the learned dictionary skm.D (i.e. the cluster centroids)\n",
    "X_test_proj = skm.transform(X_test)\n",
    "display(\n",
    "    X_test.shape,  # n_freqs x n_patches\n",
    "    X_test_proj.shape,  # n_centroids x n_patches\n",
    ")\n",
    "plt.subplot(121); plt.plot(X_test[0], X_test[1], 'b.')  # All 2 freq dims of the test data\n",
    "plt.subplot(122); plt.plot(X_test_proj[0], X_test_proj[1], 'b.')  # Just the first two dims of X_test_proj (= first 2 PCs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the patches (= time = samples) dimension for each cluster centroid (= over-completion of freqs)\n",
    "#   - Reduces dimensionality\n",
    "#   - Forgets time structure (we don't need to mess with alignment -- but we do lose sequential structure of songs)\n",
    "\n",
    "def agg_over_time(X: 'np.ndarray[n_centroids, n_patches]', aggs: List[str]) -> 'pd.DataFrame[n_centroids, n_aggs]':\n",
    "    '''\n",
    "    Aggregate each centroid row X[i,:] using each agg function ('mean', 'std', 'min', 'max', etc.)\n",
    "    '''\n",
    "    return pd.DataFrame(OrderedDict({\n",
    "        agg: {\n",
    "            'mean':     lambda X: np.mean(X, axis=1),\n",
    "            'std':      lambda X: np.std(X, axis=1),\n",
    "            'min':      lambda X: np.min(X, axis=1),\n",
    "            'max':      lambda X: np.max(X, axis=1),\n",
    "            'median':   lambda X: np.median(X, axis=1),\n",
    "            'skewness': lambda X: scipy.stats.skew(X, axis=1),\n",
    "            'kurtosis': lambda X: scipy.stats.kurtosis(X, axis=1),\n",
    "            'dmean':    lambda X: np.mean(np.diff(X, axis=1), axis=1),\n",
    "            'dstd':     lambda X: np.std(np.diff(X, axis=1), axis=1),\n",
    "            'dmean2':   lambda X: np.mean(np.diff(np.diff(X, axis=1), axis=1), axis=1),\n",
    "            'dstd2':    lambda X: np.std(np.diff(np.diff(X, axis=1), axis=1), axis=1),\n",
    "        }[agg](X)\n",
    "        for agg in aggs\n",
    "    }))\n",
    "\n",
    "# A friendly df of the aggregated centroid features [make tidy?]\n",
    "#   - (n_centroids, n_patches) -> (n_centroids, n_aggs)\n",
    "X_test_proj_agg_df = agg_over_time(X_test_proj, [\n",
    "    'mean',\n",
    "    'std',\n",
    "    'max',\n",
    "])\n",
    "\n",
    "# The raw feature vector, which should finally be amenable to vanilla classification\n",
    "#   - (n_centroids, n_patches) -> (n_centroids * n_aggs,)\n",
    "X_test_proj_agg_flat = X_test_proj_agg_df.T.values.flatten()\n",
    "\n",
    "display(\n",
    "    X_test_proj.shape,\n",
    "    X_test_proj_agg_df.shape,\n",
    "    X_test_proj_agg_df,\n",
    "    X_test_proj_agg_flat.shape,\n",
    "    X_test_proj_agg_flat,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio paths\n",
    "audio_paths = pd.DataFrame([\n",
    "    OrderedDict(\n",
    "        source=path.split('/')[-4],\n",
    "        species_code=path.split('/')[-3],\n",
    "        title=os.path.splitext(path.split('/')[-1])[0],\n",
    "        path=path,\n",
    "    )\n",
    "    for path in glob.glob(f'{peterson_dir}/*/audio/*')\n",
    "])\n",
    "display(\n",
    "    audio_paths.shape,\n",
    "    audio_paths[:5],\n",
    "    audio_paths.groupby(['source', 'species_code']).count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio from paths\n",
    "recs_2ch = (audio_paths\n",
    "    # [lambda df: df.species_code == 'wlswar'].reset_index(drop=True)  # For faster dev\n",
    "    # [:5]  # For faster dev\n",
    "    .assign(audio=lambda df: df.reset_index(drop=True).apply(axis=1, func=lambda rec:\n",
    "        (\n",
    "            # TODO Extract a reusable progress function (e.g. for next cell)\n",
    "            print(f'Loading audio {rec.name + 1}/{len(df)}: {rec.path}') if rec.name % (np.ceil(len(df) / 5) or 1) == 0 else None,\n",
    "            audiosegment.from_file(rec.path),\n",
    "        )[-1]\n",
    "    ))\n",
    ")\n",
    "display(\n",
    "    recs_2ch.shape,\n",
    "    recs_2ch.audio[:5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = (recs_2ch\n",
    "    .assign(\n",
    "        # Merge stereo to mono so we don't get confused when handling samples (we don't care about stereo vs. mono)\n",
    "        audio=lambda df: df.audio.apply(lambda audio:\n",
    "            audio.resample(channels=1, sample_rate_Hz=standard_sample_rate_hz)\n",
    "            # audio.set_channels(1)  # TODO Any loss in fidelity by using .resample(channels=1)?\n",
    "        ),\n",
    "    )\n",
    "    .assign(\n",
    "        # Materialize audio samples\n",
    "        samples=lambda df: df.audio.map(lambda audio: audio.to_numpy_array()),\n",
    "    )\n",
    "    .pipe(df_reorder_cols, last=['path'])\n",
    ")\n",
    "display(\n",
    "    recs.shape,\n",
    "    recs[:5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names for easier dev (better autocomplete)\n",
    "rec0 = recs.iloc[0]\n",
    "audio0 = rec0.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_over_time(X: 'np.ndarray[k, p]', aggs: List[str]) -> 'pd.DataFrame[k, a]':\n",
    "    '''\n",
    "    Aggregate each centroid row X[i,:] using each agg function ('mean', 'std', 'min', 'max', etc.)\n",
    "    '''\n",
    "    return pd.DataFrame(OrderedDict({\n",
    "        agg: {\n",
    "            'mean':     lambda X: np.mean(X, axis=1),\n",
    "            'std':      lambda X: np.std(X, axis=1),\n",
    "            'min':      lambda X: np.min(X, axis=1),\n",
    "            'max':      lambda X: np.max(X, axis=1),\n",
    "            'median':   lambda X: np.median(X, axis=1),\n",
    "            'skewness': lambda X: scipy.stats.skew(X, axis=1),\n",
    "            'kurtosis': lambda X: scipy.stats.kurtosis(X, axis=1),\n",
    "            'dmean':    lambda X: np.mean(np.diff(X, axis=1), axis=1),\n",
    "            'dstd':     lambda X: np.std(np.diff(X, axis=1), axis=1),\n",
    "            'dmean2':   lambda X: np.mean(np.diff(np.diff(X, axis=1), axis=1), axis=1),\n",
    "            'dstd2':    lambda X: np.std(np.diff(np.diff(X, axis=1), axis=1), axis=1),\n",
    "        }[agg](X)\n",
    "        for agg in aggs\n",
    "    }))\n",
    "\n",
    "def featurize(\n",
    "    recs,\n",
    "    f_min=1000,\n",
    "    mel_bins=40,\n",
    "    hop_length=256,\n",
    "    frame_length=512,\n",
    "    frame_window='hann',\n",
    "    patch_length=4,\n",
    "    pca_whiten_var=.99,\n",
    "    k=512,\n",
    "    aggs=['mean', 'std', 'max'],\n",
    "    verbose=False,\n",
    ") -> 'np.ndarray[k * n_aggs]':\n",
    "    \"\"\"\n",
    "    Featurization pipeline\n",
    "\n",
    "    Params\n",
    "        |                  | defaults      | [SP14]         | [SBF16]       |\n",
    "        |------------------|---------------|----------------|---------------|\n",
    "        | sample_rate      | 22050         | 44100          | 22050\n",
    "        | f_min            | 1000          | 500            | 2000\n",
    "        |   f_max          | 11025         | 22050          | 11025\n",
    "        | mel_bins (f)     | 40            | 40             | 40\n",
    "        | hop_length       | 256 (12ms)    | 1024 (23ms)    | 32 (1.5ms)\n",
    "        | frame_length     | 512 (23ms)    | 1024 (23ms)    | 256 (12ms)\n",
    "        |   overlap_frac   | .5            | 0              | .875\n",
    "        |   t/s            | 86            | 43             | 689\n",
    "        | frame_window     | hann          | hamming        | hann\n",
    "        | norm             | [TODO]        | RMS+median     | [TODO]\n",
    "        | patch_length (p) | 4 (46ms)      | ~4 (~93ms)     | ~16 (~22ms)\n",
    "        | pca_whiten_var   | .99           | —              | .99\n",
    "        | k                | 500           | 500            | ~512\n",
    "        | aggs             | μ,σ,max       | μ,σ            | ~μ,σ,max\n",
    "        |   a              | 3             | 2              | ~3\n",
    "        |   features       | 1500          | 1000           | ~1536\n",
    "\n",
    "    Pipeline\n",
    "        | audio      | (samples,)| (22050/s,)    | (44100/s)      | (22050/s,)\n",
    "        | melspectro | (f, t)    | (40, 86/s)    | (40, 43/s)     | (40, 689/s)\n",
    "        | patches    | (f, p, t) | (40, 4, 86/s) | (40, ~4, 43/s) | (40, ~16, 689/s)\n",
    "        | projected  | (k, t)    | (500, 86/s)   | (500, 43/s)    | (~512, 689/s)\n",
    "        | aggregated | (k, a)    | (500, 3)      | (500, 2)       | (~512, ~3)\n",
    "        | features   | (k*a,)    | (1500,)       | (1000,)        | (~1536,)\n",
    "    \"\"\"\n",
    "\n",
    "    (rec, audio, x, sample_rate) = unpack_rec(rec_or_audio_or_signal)\n",
    "\n",
    "    # Show all input params and derived params back to the user\n",
    "    _g = lambda x: '%.3g' % x\n",
    "    _samples = sample_rate\n",
    "    _f = mel_bins\n",
    "    _t_s = '%s/s' % _g(sample_rate / hop_length)\n",
    "    _t = int(sample_rate / hop_length * audio.duration_seconds)\n",
    "    _p = patch_length\n",
    "    _k = k\n",
    "    _a = len(aggs)\n",
    "    _ka = k * len(aggs)\n",
    "    if verbose:\n",
    "        print(f'audio:\\n  {audio.name}')\n",
    "        print('\\nParams:')\n",
    "        print(pd.Series(OrderedDict({\n",
    "            'audio': repr('...%s' % audio.name[-20:]),\n",
    "            '  channels': '%s ch' % audio.channels,\n",
    "            '  sample_width': '%s bit' % (audio.sample_width * 8),\n",
    "            '  sample_rate': '%s Hz' % sample_rate,\n",
    "            '  duration': '%s s' % _g(audio.duration_seconds),\n",
    "            'f_min': '%s Hz' % f_min,\n",
    "            '  f_max': '%s Hz' % (sample_rate // 2),\n",
    "            'mel_bins (f)': mel_bins,\n",
    "            'hop_length': '%s (%s ms)' % (hop_length, _g(1 / sample_rate * hop_length * 1000)),\n",
    "            'frame_length': '%s (%s ms)' % (frame_length, _g(1 / sample_rate * frame_length * 1000)),\n",
    "            '  overlap_frac': _g(1 - hop_length / frame_length),\n",
    "            '  t/s': _t_s,\n",
    "            '  t': _t,\n",
    "            'frame_window': repr(frame_window),\n",
    "            'norm': '[TODO]',  # TODO\n",
    "            'patch_length (p)': '%s (%s ms)' % (_p, _g(1 / sample_rate * _p * 1000)),\n",
    "            'pca_whiten_var': pca_whiten_var,\n",
    "            'k': k,\n",
    "            'aggs': repr(aggs),\n",
    "            '  a': _a,\n",
    "            'features': k * _a,\n",
    "        })))\n",
    "        print('\\nPipeline:')\n",
    "        print(pd.Series(OrderedDict({\n",
    "            'audio':      f'({_samples},)  (samples,)',\n",
    "            'melspectro': f'({_f}, {_t_s})      (f, t)',\n",
    "            'patches':    f'({_f}, {_p}, {_t_s})   (f, p, t)',\n",
    "            'projected':  f'({_k}, {_t_s})      (k, t)',\n",
    "            'aggregated': f'({_k}, {_a})      (k, a)',\n",
    "            'features':   f'({_ka},)      (k*a,)',\n",
    "        })))\n",
    "        print()\n",
    "\n",
    "    # audio (samples,) -> melspectro (f,t)\n",
    "    # TODO\n",
    "    ... = melspectro(rec, nperseg=..., overlap=..., ...)\n",
    "\n",
    "    # melspectro (f,t) -> patches (f,p,t)\n",
    "    # TODO\n",
    "\n",
    "    # patches (f,p,t) -> projected (k,t)\n",
    "    #   - TODO The above was written for 1 rec, but we need to take N recs for batch training, for skm.fit(...)\n",
    "    #   - TODO Think about different handling of train vs. test (e.g. skm)\n",
    "    if train:\n",
    "        skm = SKM(k=10)\n",
    "        skm.fit(recs)  # TODO Refactor to allow for this batch operation\n",
    "        ...  # TODO\n",
    "    else:\n",
    "        projected = skm.transform(patches)\n",
    "\n",
    "    # projected (k,t) -> aggregated (k,a)\n",
    "    aggregated_df = agg_over_time(projected, aggs)\n",
    "\n",
    "    # aggregated (k,a) -> features (k*a,)\n",
    "    features = aggregated_df.T.values.flatten()\n",
    "\n",
    "    return features\n",
    "\n",
    "featurize(recs.iloc[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Need to return something from featurize\n",
    "(recs\n",
    "    [:5]\n",
    "    .apply(axis=1, func=featurize, verbose=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example classifier\n",
    "#\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "#\n",
    "# # TODO Audio files -> this stuff\n",
    "# X_train = featurize(...)\n",
    "# y_train = ...\n",
    "# X_test = feature(...)\n",
    "#\n",
    "# knn = KNeighborsClassifier(3)\n",
    "# knn.fit(X_train, y_train)\n",
    "#\n",
    "# knn.predict(X_test)\n",
    "# knn.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bubo-features (PYTHONSTARTUP)",
   "language": "python",
   "name": "bubo-features (PYTHONSTARTUP)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
