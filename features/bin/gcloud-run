#!/usr/bin/env python
#
# WARNING Full of hacks
#
# How to launch a vanilla node (e.g. f1-micro):
#   bin/gcloud-run --keep=... --machine-type=... --boot-disk-size=25g --boot-disk-type=pd-standard --disk= --vm-init= --container-init= true
#
# Notes for different images:
#   - cos
#       - docker v17 [https://cloud.google.com/container-optimized-os/docs/release-notes]
#   - coreos
#       - docker v18 [https://coreos.com/releases/]
#       - --username=core [https://coreos.com/os/docs/latest/booting-on-google-compute-engine.html]
#       - [I can't get `ssh core@...` to work...]
#
# Example auth, e.g. for deploys [XXX Out of date]:
#   GOOGLE_APPLICATION_CREDENTIALS=~/hack/.bubo-secrets/gcloud-service-account-bubo.json bin/gcloud-run ...

import atexit
from datetime import datetime, timedelta
import json
import os
from pathlib import Path
import re
import shlex
import subprocess
import sys
import time

from attrdict import AttrDict
import click
import crayons
import dataclasses
from dataclasses import dataclass
from potoo.pretty import pp
from potoo.util import shell

from constants import project, zone

# click: Default option(show_default=True)
_click_option = click.option
click.option = lambda *args, **kwargs: _click_option(*args, **{'show_default': True, **kwargs})

code_dir = Path(__file__).parent.parent.resolve()
bin_dir = code_dir / 'bin'


# FIXME click doesn't exit nonzero on -h/--help [wat]
#   - https://github.com/pallets/click/issues/702
@click.command(context_settings=dict(
    help_option_names=['-h', '--help'],
    max_content_width=click.get_terminal_size()[0],
))
# Project/zone
@click.option('--project', default=project)
@click.option('--zone', default=zone)
# Instance name
@click.option('--instance-name', default='%(instance_name_prefix)s-%(timestamp)s')
@click.option('--instance-name-prefix', default='gcloud-run')
# Machine type
#   - https://cloud.google.com/compute/pricing
#
#                      type  cpu   mem  $[   dem /  pre ]/mo  $[    dem /  pre  ]/d  $[    dem  /   pre  ]/hr
#
#                  f1-micro    1   .6g  $[     4 /    3 ]/mo  $[    .19 /   .10 ]/d  $[   .0076 /  .0035 ]/hr
#                  g1-small    1  1.7g  $[    13 /    5 ]/mo  $[    .62 /   .17 ]/d  $[   .026  /  .0070 ]/hr
#
#              n1-highcpu-2    2    2g  $[    36 /   11 ]/mo  $[   1.7  /   .48 ]/d  $[   .071  /  .015  ]/hr
#              n1-highcpu-4    4    4g  $[    72 /   22 ]/mo  $[   3.4  /   .72 ]/d  $[   .14   /  .030  ]/hr
#              n1-highcpu-8    8    7g  $[   145 /   44 ]/mo  $[   6.7  /  1.4  ]/d  $[   .28   /  .060  ]/hr
#             n1-highcpu-16   16   14g  $[   290 /   88 ]/mo  $[  14    /  2.9  ]/d  $[   .57   /  .12   ]/hr
#             n1-highcpu-32   32   29g  $[   580 /  175 ]/mo  $[  27    /  5.8  ]/d  $[  1.1    /  .24   ]/hr
#             n1-highcpu-64   64   58g  $[  1159 /  350 ]/mo  $[  54    / 12    ]/d  $[  2.3    /  .48   ]/hr
#             n1-highcpu-96   96   86g  $[  1739 /  526 ]/mo  $[  82    / 17    ]/d  $[  3.4    /  .72   ]/hr
#
#             n1-standard-2    2    7g  $[    49 /   15 ]/mo  $[   2.4  /   .48 ]/d  $[   .10   /  .020  ]/hr
#             n1-standard-4    4   15g  $[    97 /   29 ]/mo  $[   4.6  /   .96 ]/d  $[   .19   /  .040  ]/hr
#             n1-standard-8    8   30g  $[   194 /   58 ]/mo  $[   9.1  /  1.9  ]/d  $[   .38   /  .080  ]/hr
#            n1-standard-16   16   60g  $[   388 /  116 ]/mo  $[  18    /  3.8  ]/d  $[   .76   /  .16   ]/hr
#            n1-standard-32   32  120g  $[   776 /  233 ]/mo  $[  36    /  7.7  ]/d  $[  1.5    /  .32   ]/hr
#            n1-standard-64   64  240g  $[  1553 /  467 ]/mo  $[  73    / 16    ]/d  $[  3.0    /  .64   ]/hr
#            n1-standard-96   96  360g  $[  2330 /  700 ]/mo  $[ 109    / 23    ]/d  $[  4.6    /  .96   ]/hr
#
#              n1-highmem-2    2   13g  $[    61 /   18 ]/mo  $[   2.9  /   .72 ]/d  $[   .12   /  .025  ]/hr
#              n1-highmem-4    4   26g  $[   121 /   37 ]/mo  $[   5.8  /  1.2  ]/d  $[   .24   /  .050  ]/hr
#              n1-highmem-8    8   52g  $[   242 /   73 ]/mo  $[  11    /  2.4  ]/d  $[   .47   /  .10   ]/hr
#             n1-highmem-16   16  104g  $[   484 /  146 ]/mo  $[  23    /  4.8  ]/d  $[   .95   /  .20   ]/hr
#             n1-highmem-32   32  208g  $[   968 /  292 ]/mo  $[  45    /  9.6  ]/d  $[  1.9    /  .40   ]/hr
#             n1-highmem-64   64  416g  $[  1936 /  584 ]/mo  $[  91    / 19    ]/d  $[  3.8    /  .80   ]/hr
#             n1-highmem-96   96  624g  $[  2904 /  876 ]/mo  $[ 136    / 29    ]/d  $[  5.7    / 1.2    ]/hr
#
#                     model  gpu   mem  $[   dem /  pre ]/mo  $[    dem /   pre ]/d  $[   dem   /  pre   ]/h
#
#  NVIDIA Tesla K80 (GDDR5)    1   12g  $[   230 /   99 ]/mo  $[  11    /   3.2 ]/d  $[   .45   /  .14   ]/h
#  NVIDIA Tesla K80 (GDDR5)    2   24g  $[   460 /  198 ]/mo  $[  22    /   6.5 ]/d  $[   .90   /  .27   ]/h
#  NVIDIA Tesla K80 (GDDR5)    4   48g  $[   920 /  396 ]/mo  $[  43    /  13   ]/d  $[  1.8    /  .54   ]/h
#  NVIDIA Tesla K80 (GDDR5)    8   96g  $[  1840 /  792 ]/mo  $[  86    /  26   ]/d  $[  3.6    / 1.1    ]/h
#
#  NVIDIA Tesla P100 (HBM2)    1   16g  $[   746 /  314 ]/mo  $[  35    /  10   ]/d  $[  1.5    /  .43   ]/h
#  NVIDIA Tesla P100 (HBM2)    2   32g  $[  1492 /  628 ]/mo  $[  70    /  21   ]/d  $[  2.9    /  .86   ]/h
#  NVIDIA Tesla P100 (HBM2)    4   64g  $[  2984 / 1256 ]/mo  $[ 140    /  41   ]/d  $[  5.8    / 1.7    ]/h
#
#  NVIDIA Tesla V100 (HBM2)    1   16g  $[  1267 /  540 ]/mo  $[  60    /  18   ]/d  $[  2.5    /  .74   ]/h
#  NVIDIA Tesla V100 (HBM2)    2   32g  $[  2534 / 1080 ]/mo  $[ 120    /  36   ]/d  $[  5.0    / 1.5    ]/h
#  NVIDIA Tesla V100 (HBM2)    4   64g  $[  5068 / 2160 ]/mo  $[ 238    /  71   ]/d  $[  9.9    / 3.0    ]/h
#  NVIDIA Tesla V100 (HBM2)    8  128g  $[ 10140 / 4320 ]/mo  $[ 476    / 142   ]/d  $[ 20      / 5.9    ]/h
#
@click.option('--machine-type', default='n1-standard-4', help='https://cloud.google.com/compute/pricing')
@click.option('--preemptible/--no-preemptible', default=False)
# CPU platform
#   - https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform
#   - https://cloud.google.com/compute/docs/regions-zones/#available
@click.option('--min-cpu-platform', default='Intel Skylake')
# Instance lifetime
@click.option('--keep', default=None, help='Instance name to create and keep (no delete)')
@click.option('--reuse', default=None, help='Instance name to reuse (no create, delete, await)')
@click.option('--create-instance/--no-create-instance', default=True)
@click.option('--delete-instance/--no-delete-instance', default=True)
# Image
#   - `gcloud compute images list`
#   - https://cloud.google.com/compute/docs/images
#   - $.085/gb/mo
@click.option('--image-project', default='%(project)s')
@click.option('--image-family', default='bubo-cache')
@click.option('--image', default=None)
# Disks
#   - https://cloud.google.com/compute/docs/disks/
#   - pd-standard
#       - $.04/gb/mo
#       - Throughput r  = max(  180,  12*size/100gb) mb/s [max at  1500gb, $ 60/mo]
#       - Throughput w  = max(  120,  12*size/100gb) mb/s [max at  1000gb, $ 40/mo]
#       - Ops        r  = max( 3000,  75*size/100gb)  r/s [max at  4000gb, $160/mo]
#       - Ops        w  = max(15000, 150*size/100gb)  w/s [max at 10000gb, $400/mo]
#   - pd-ssd
#       - $.17/gb/mo
#       - Throughput r = max(  240 –  1200,   48*size/100gb) mb/s [max at 500 – 2500 gb, $ 85 – 425 /mo]
#       - Throughput w = max(  240 –   400,   48*size/100gb) mb/s [max at 500 –  833 gb, $ 85 – 142 /mo]
#       - Ops        r = max(15000 – 60000, 3000*size/100gb) mb/s [max at 500 – 2000 gb, $ 85 – 340 /mo]
#       - Ops        w = max(15000 – 30000, 3000*size/100gb) mb/s [max at 500 – 1000 gb, $ 85 – 170 /mo]
#   - Examples
#       - pd-standard  100gb:  $4/mo,  12mb/s r,  12mb/s w
#       - pd-standard  200gb:  $8/mo,  24mb/s r,  24mb/s w
#       - pd-ssd       100gb: $17/mo,  48mb/s rw
#       - pd-standard  500gb: $20/mo,  60mb/s r,  60mb/s w
#       - pd-standard  750gb: $30/mo,  90mb/s r,  90mb/s w
#       - pd-ssd       200gb: $34/mo,  96mb/s rw
#       - pd-standard 1000gb: $40/mo, 120mb/s r, 120mb/s w
#       - pd-standard 1500gb: $60/mo, 180mb/s r, 120mb/s w
#       - pd-ssd       500gb: $85/mo, 240mb/s rw
@click.option('--boot-disk-size', default='200g')
@click.option('--boot-disk-type', default='pd-standard', help='pd-standard | pd-ssd')
@click.option('--disk-name', default='bubo-data-standard-1')
@click.option('--disk-mode', default='ro')
@click.option('--disk', default='name=%(disk_name)s,device-name=%(disk_name)s,boot=no,auto-delete=no,mode=%(disk_mode)s')
# Network tier
#   - https://cloud.google.com/network-tiers/pricing
#   - Standard: Egress NA -> *[$.085/gb]
#   - Premium:  Egress NA -> NA[$.105/gb], China[$.46/gb], Oceania[$.19/gb], *[$.12/gb]
#   - Region us-west1 only supports premium
@click.option('--network-tier', default='PREMIUM')
# Service account
#   - By default, gce uses the "Compute Engine default service account" with a limited set of --scopes
#   - This default overrides --scopes to give full access to all gcloud apis
#   - If you want to change the service account, use --service-account or else you'll have to manually `gcloud auth
#     activate-service-account` to override it (and `gcloud auth` takes precedence over GOOGLE_APPLICATION_CREDENTIALS)
@click.option('--service-account', default=None)
@click.option('--scopes', default='https://www.googleapis.com/auth/cloud-platform')
# vm/container
#   - Can only mount disk here, not also gs [because gcsfuse is too difficult to install into cos...]
#   - TODO Clean up --disk / --vm-init: tight coupling, wouldn't use one without the other
#   - HACK Need bash because cos mounts are noexec (ugh) [https://stackoverflow.com/a/50279396/397334]
@click.option('--vm/--no-vm', default=False, help='--vm is an alias for --no-container')
@click.option('--vm-init', default='sudo bash vm-bin/mount-disk-bubo-data %(disk_name)s')
@click.option('--container/--no-container', default=True, help='Run command in container, else run in instance')
@click.option('--container-init', default='vm-bin/mount-bubo-data-%(disk_mode)s')
@click.option('--container-pull/--no-container-pull', default=False, help='True if creating an instance, else false')
@click.option('--container-push/--no-container-push', default=False)
@click.option('--container-image', default='gcr.io/%(project)s/bubo/features:latest')
@click.option('--container-name', default='%(instance_name)s')
@click.option('--container-vols', default='-v/mnt/disks/disk-bubo-data:/mnt/disks/disk-bubo-data')
@click.option('--container-ports', default='-p80:80 -p8000:8000 -p8888:8888')  # TODO Expose a simpler --ports option (here and below)
# Send container logs to stackdriver
#   - Disabled by default, since ncurses stuff like htop/glances produces a ton of noise
#   - Docs: https://cloud.google.com/community/tutorials/docker-gcplogs-driver
#   - Docs: https://docs.docker.com/config/containers/logging/gcplogs/
#   - Pricing ($.5/gb/mo): https://cloud.google.com/stackdriver/pricing
@click.option('--container-logging/--no-container-logging', default=False)
@click.option('--container-run/--no-container-run', default=True, help='`docker run`')
@click.option('--container-exec/--no-container-exec', default=False, help='`docker exec`')
@click.option('--container-attach/--no-container-attach', default=False, help='`docker attach`')
@click.option('--sync-code/--no-sync-code', default=True, help='rsync code_dir to remote')
# TODO Ugh, clean up this --docker-pull/--docker-run/--docker-exec mess
@click.option('--docker-pull', default=' '.join([
    'sudo docker run -it',
    '-v/var/run/docker.sock:/var/run/docker.sock',
    'google/cloud-sdk:203.0.0',
    'bash -c "gcloud auth configure-docker --quiet && docker pull %(container_image)s"',
]))
@click.option('--docker-build', default=' '.join([
    # TODO Document v18 vs. v17 like docker-build-push-gcloud
    'sudo docker run -it',
    '-v/var/run/docker.sock:/var/run/docker.sock',
    '-v"$PWD"/build:/build',
    '-w/build',
    'docker:18.03.1',
    'docker build . --cache-from=%(container_image)s -t %(container_image)s',
    # 'docker build . -t %(container_image)s',
]))
@click.option('--docker-push', default=' '.join([
    # XXX Unused
    'sudo docker run -it',
    '-v/var/run/docker.sock:/var/run/docker.sock',
    'google/cloud-sdk:203.0.0',
    'bash -c "gcloud auth configure-docker --quiet && docker push %(container_image)s"',
]))
@click.option('--docker-run', default=' '.join([
    # Don't unconditionally pull, since it busts our local cache and we have to rebuild from the pulled image
    #   - And don't unconditionally push, since it slows down our dev loop
    '%(maybe_docker_pull)s &&',
    '%(docker_build)s &&',
    '%(maybe_docker_push)s &&',
    'sudo docker run -it',
    '--privileged --restart=no --rm --name=%(container_name)s -eCONTAINER_NAME=%(container_name)s',
    '%(docker_run_opts)s',
    '%(container_vols)s',
    '%(container_ports)s',
    '%(container_logging)s',
    '%(container_image)s',
    '%(command)s',
]))
@click.option('--docker-run-opts', default=' '.join([
    # Increase /dev/shm 64m -> 10g to avoid "No space left on device" errors from sklearn/joblib
    #   - https://stackoverflow.com/questions/40115043/no-space-left-on-device-error-while-fitting-sklearn-model
    #   - https://github.com/joblib/joblib/issues/168
    '--shm-size=10g',
]))
@click.option('--docker-exec', default=' '.join([
    'sudo docker exec -it',
    '%(container_name)s',
    '%(command)s',
]))
@click.option('--docker-attach', default=' '.join([
    'sudo docker attach',
    '%(container_name)s',
]))
# Command
@click.option('--await-ready/--no-await-ready', default=True)
@click.option('--username', default='bubo')
@click.argument('command', nargs=1, required=False)  # Cmd as a single shell token, i.e. quote the whole thing
def main(
    project, zone,
    instance_name, instance_name_prefix,
    machine_type, preemptible, min_cpu_platform,
    keep, reuse, create_instance, delete_instance,
    image_project, image_family, image,
    boot_disk_size, boot_disk_type, disk_name, disk_mode, disk,
    network_tier,
    service_account, scopes,
    vm, vm_init,
    container, container_init, container_pull, container_push,
    container_image, container_name, container_vols, container_ports, container_logging,
    container_run, container_exec, container_attach, sync_code,
    docker_pull, docker_build, docker_push, docker_run, docker_run_opts, docker_exec, docker_attach,
    await_ready, username, command,
):

    gcloud = GCloud(
        project=project,
    )

    # Args
    #   - TODO Do these substitutions generically so you don't have to manually specify each allowed subst
    instance_name = instance_name % dict(
        instance_name_prefix=instance_name_prefix,
        timestamp=re.sub('[^0-9T]', '-', datetime.utcnow().isoformat()).lower(),
    )
    # TODO Would we want `--keep=x --reuse=x` to mean "assume x exists" (like `--reuse=x`) or "boot x if not exists"?
    assert not (keep and reuse)
    if keep:
        delete_instance = False
        instance_name = keep
    if reuse:
        create_instance = False
        delete_instance = False
        await_ready = False
        instance_name = reuse
    image_project = image_project % dict(project=project)
    if disk:
        disk = disk % dict(disk_name=disk_name, disk_mode=disk_mode)
    container_init = container_init % dict(disk_mode=disk_mode)
    if vm:
        container = False
    if vm_init:
        vm_init = vm_init % dict(disk_name=disk_name)
    container_pull = container_pull or create_instance  # Always pull if the instance is fresh
    container_image = container_image % dict(project=project)
    container_name = container_name % dict(instance_name=instance_name)
    container_logging = '--log-driver=gcplogs' if container_logging else ''
    container_op = (
        'attach' if container_attach else
        'exec' if container_exec else
        'run'
    )
    assert not sync_code or container_op in ['run', 'exec']
    if not command:
        command = 'bash'
    command = command % dict(instance_name=instance_name)
    if container and container_op == 'run' and container_init:
        command = ' && '.join([container_init, command])
    command = 'bash -x -c %s' % shlex.quote(command)
    docker_pull = docker_pull % dict(
        container_image=shlex.quote(container_image),
    )
    docker_build = docker_build % dict(
        container_image=shlex.quote(container_image),
    )
    docker_push = docker_push % dict(
        container_image=shlex.quote(container_image),
    )
    docker_run = docker_run % dict(
        maybe_docker_pull=docker_pull if container_pull else ':',
        docker_build=docker_build,
        maybe_docker_push=docker_push if container_push else ':',
        container_name=shlex.quote(container_name),
        docker_run_opts=docker_run_opts,
        container_vols=container_vols,
        container_ports=container_ports,
        container_logging=container_logging,
        container_image=shlex.quote(container_image),
        command=command,
    )
    docker_exec = docker_exec % dict(
        container_name=shlex.quote(container_name),
        command=command,
    )
    docker_attach = docker_attach % dict(
        container_name=shlex.quote(container_name),
        command=command,
    )

    # Delete instance on exit
    #   - Use atexit so we can exec
    if delete_instance:
        def _atexit():
            gcloud('compute', 'instances', 'delete', instance_name,
                zone=zone,
                _mode='async',
            )
        atexit.register(_atexit)

    # Create instance
    if create_instance:
        print(color('blue', 'Creating instance...'))
        [res] = gcloud('beta', 'compute', 'instances', 'create', instance_name,
            zone=zone,
            machine_type=machine_type,
            preemptible=preemptible,
            min_cpu_platform=min_cpu_platform,
            image_project=image_project,
            image_family=image_family,
            image=image,
            boot_disk_size=boot_disk_size,
            boot_disk_type=boot_disk_type,
            disk=disk,
            network_tier=network_tier,
            service_account=service_account,
            scopes=scopes,
            # tags='http-server,https-server',  # For ports 80/443
        )
        assert res['name'] == instance_name
        external_ip = res['networkInterfaces'][0]['accessConfigs'][0]['natIP']
        print(color('blue', 'Created instance:'))
        print(color('blue', '  zone: %s' % zone))
        print(color('blue', '  instance_name: %s' % instance_name))
        print(color('blue', '  external_ip: %s' % external_ip))

    # Wait until ssh'ing into the instance succeeds
    if await_ready:
        print(color('blue', 'Awaiting instance ready...'))
        retry(times=60, delay_s=1, f=lambda: (
            gcloud('compute', 'ssh', f'{username}@{instance_name}',
                zone=zone,
                _mode='no-json',
                _end_args=['--', '-tq', 'true'],
            )
        ))
        print(color('blue', 'Instance ready'))
        print(color('blue', '  zone: %s' % zone))
        print(color('blue', '  instance_name: %s' % instance_name))
        if create_instance:
            print(color('blue', '  external_ip: %s' % external_ip))

    # Run vm_init
    if create_instance and vm_init:

        print(color('blue', f'Syncing vm-bin/ to instance[{instance_name}]...'))
        shell(
            '%(bin_dir)s/rsync-vm %(code_dir)s/vm-bin/ %(instance_name)s:vm-bin/',
            bin_dir=bin_dir,
            code_dir=code_dir,
            instance_name=instance_name,
        )

        print(color('blue', f'Running --vm-init'))
        gcloud('compute', 'ssh', f'{username}@{instance_name}',
            zone=zone,
            _mode='no-json',
            _end_args=['--', '-tq', vm_init],
        )

    # Run command
    #   - WARNING Careful with retry here: need to distinguish transient (network) vs. non-transient (command) errors
    if command:

        # Run cmd in vm
        if not container:
            print(color('blue', f'Running command on instance[{instance_name}]...'))
            gcloud('compute', 'ssh', f'{username}@{instance_name}',
                zone=zone,
                _mode='exec',
                _end_args=['--', '-tq', command],
            )
        else:

            # Sync code (to container)
            if sync_code:
                print(color('blue', 'Syncing code_dir[%s] to container on %s...' % (code_dir, ' / '.join([
                    f'instance[{instance_name}]', f'image[{container_image}]', f'container[{container_name}]',
                ]))))

                # If docker run, then rsync-vm
                if container_op == 'run':
                    shell(
                        '%(bin_dir)s/rsync-vm %(code_dir)s/ %(instance_name)s:build/',
                        bin_dir=bin_dir,
                        code_dir=code_dir,
                        instance_name=instance_name,
                    )

                # If docker exec, then rsync-container
                elif container_op == 'exec':
                    assert container_name == instance_name, 'TODO Add --container to bin/rsync-container (env var?)'
                    shell(
                        '%(bin_dir)s/rsync-code-to-container %(instance_name)s',
                        bin_dir=bin_dir,
                        instance_name=instance_name,
                    )

            # Run cmd via docker run/exec, or just docker attach
            print(color('blue', 'Running command on %s...' % ' / '.join([
                f'instance[{instance_name}]', f'image[{container_image}]', f'container[{container_name}]',
            ])))
            gcloud('compute', 'ssh', f'{username}@{instance_name}',
                zone=zone,
                _mode='exec',
                _end_args=[
                    '--',
                    '-tq',
                    '-L', '8888:localhost:8888',  # Tunnel port 8888
                    docker_attach if container_op == 'attach' else
                        docker_exec if container_op == 'exec' else
                        docker_run,
                ],
            )


@dataclass
class GCloud:
    """
    A thin wrapper around the gcloud cli, because it's better documented and easier to figure out than the actual
    google-cloud python libs
    """

    # Defaults
    project: str
    quiet: bool = True  # No prompts, accept defaults

    @property
    def config(self) -> dict:
        return dataclasses.asdict(self)

    def __call__(self, *args, _mode='json', **kwargs):
        assert _mode in ['json', 'no-json', 'exec', 'async']

        # Build cmd
        kwargs = {**self.config, **kwargs}  # Silently overwrite duplicate keys with user keys
        if _mode == 'response':
            # So we can parse gcloud result as json (below)
            kwargs = dict(**kwargs, format='json')  # Loudly fail if user passed a 'format' key
        gcloud_cmd = shell_cmd('gcloud', *args, **kwargs)

        # Handle mode
        if _mode == 'exec':
            repro_cmd = gcloud_cmd
            real_cmd = ['bash', '-c', 'exec %s' % repro_cmd]
        elif _mode == 'async':
            repro_cmd = 'nohup %s >>/var/log/gcloud-run-async.log &' % gcloud_cmd
            real_cmd = ['bash', '-c', repro_cmd]
        else:
            repro_cmd = ('%s --format=json' if _mode == 'json' else '%s') % gcloud_cmd
            real_cmd = ['bash', '-c', repro_cmd]
        print(color('black', f'$ {repro_cmd}'))
        # print(color('red', f'$ {real_cmd}'))  # Debug

        # Run cmd
        if _mode == 'exec':
            # Run, wait for completion, and exit with cmd's exit status
            #   - Passthru fd's (e.g. stdin/stdout/stderr)
            #   - Don't actually exec here since it wouldn't run our atexit handlers (delete instance)
            proc = subprocess.run(real_cmd)
            sys.exit(proc.returncode)
        elif _mode == 'async':
            # Run, ignore result
            #   - Assume cmd is already async via something like bash's '&', from above
            subprocess.run(real_cmd)
        else:
            # Run, wait for completion, parse output (assumes '--format=json', above)
            proc = subprocess.run(
                real_cmd,
                stdout=subprocess.PIPE if _mode == 'json' else None,
            )

            # Handle result
            if proc.returncode != 0:
                msg = 'Process exited %s' % proc.returncode
                if proc.stdout:
                    msg += ', stdout[%s]' % (
                        re.sub('\n+\s*', ' ', proc.stdout.decode().strip()),
                    )
                raise Exception(msg)
            elif _mode == 'json':
                try:
                    return json.loads(proc.stdout.decode())
                except:
                    print(color('red', 'Failed to parse json from stdout[%s]' % proc.stdout))  # TODO Fold into exc msg
                    raise


def shell_cmd(*args, _end_args=None, **kwargs) -> str:
    return ' '.join([
        *map(shlex.quote, args),
        *[
            (
                '--%s' % shlex.quote(k) if v == True else
                '--%s=%s' % (shlex.quote(k), shlex.quote(v))
            )
            for k, v in kwargs.items()
            for k in [k.replace('_', '-')]
            if v
        ],
        *map(shlex.quote, (_end_args or [])),
    ])


def retry(f, times: int, delay_s: float):
    attempt = 1
    while True:
        try:
            return f()
        except Exception as e:
            print(color('yellow', f'Retrying[{attempt}/{times}] in {delay_s}s after error: {e}'))
            time.sleep(delay_s)
            attempt += 1
            if attempt > times:
                break


def color(name: str, s: str, **kwargs) -> str:
    kwargs.setdefault('bold', True)  # Bold is great
    if not name or not sys.stdout.isatty():
        return s
    else:
        return getattr(crayons, name)(s, **kwargs)


if __name__ == '__main__':
    try:
        main()
    except (KeyboardInterrupt, EOFError):
        pass
